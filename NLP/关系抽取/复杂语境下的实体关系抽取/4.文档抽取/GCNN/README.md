# 使用文档级图卷积神经网络进行句间关系提取

# Inter-sentence Relation Extraction with Document-level Graph Convolutional Neural Network

## 摘要

句间关系抽取处理文档中许多复杂的语义关系，需要局部、非局部、句法和语义依赖。 现有方法并没有完全利用这种依赖关系。我们提出了一种新颖的句间关系提取模型，该模型在文档级图上构建了标记边缘图卷积神经网络模型。 该图是使用各种句间和句内依赖关系构建的，以捕获本地和非本地依赖信息。 为了预测实体对的关系，我们利用具有双仿射成对评分的多实例学习。 实验结果表明，我们的模型在两个生物化学数据集上实现了与最先进的神经模型相当的性能。 我们的分析表明，图中的所有类型对于句间关系提取都是有效的。

## 1 前言

命名实体之间的语义关系通常跨越多个句子。为了提取句间关系，大多数方法利用远程监督自动生成文档级语料库（Peng et al., 2017; Song et al., 2018）。 最近，Verga 等人。  (2018) 引入了多实例学习 (MIL)（Riedel 等人，2010 年；Surdeanu 等人，2012 年）来处理文档中对目标实体的多次提及。

句间关系不仅依赖于本地依赖，也依赖于非本地依赖。在句内关系提取 (RE) 中，依赖树通常用于提取语义关系的局部依赖关系 (Culotta and Sorensen, 2004; Liu et al., 2015)。 然而，这种依赖对于句间 RE 是不够的，因为不同的句子有不同的依赖树。 图 1 说明了催产素和低血压之间的这种情况。 为了捕捉它们的关系，必须将共同引用的实体 Oxytocin 和 Oxt 联系起来。RNN 和 CNN，常用于句内 RE（Zeng 等，2014；dos Santos 等，2015；Zhou 等，2016b；Lin 等，2016）对较长的序列无效 （Sahu 和 Anand，2018）因此未能捕获此类非本地依赖项。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/GCNN/figure/figure_1.png)

图 1：命名实体之间具有非本地依赖关系的句子。红色箭头表示共同引用实体之间的关系，黄色箭头表示语义依赖关系。 改编自 CDR 数据集的示例（Wei 等，2015）。

我们提出了一种新颖的句间 RE 模型，该模型在文档级图上构建了一个带标签的边缘图 CNN (GCNN) 模型（Marcheggiani 和 Titov，2017 年）。图节点对应单词，边表示它们之间的局部和非局部依赖性。 文档级图是通过将单词与来自句法解析和顺序信息的局部依赖以及来自共指解析和其他语义依赖的非局部依赖连接起来形成的 (Peng et al., 2017)。我们使用基于 MIL 的双仿射成对评分函数 (Verga et al., 2018) 在实体节点表示上推断实体之间的关系。

我们的贡献是三方面的。 首先，我们提出了一种使用 GCNN 来捕获本地和非本地依赖关系的句间 RE 新模型。 其次，我们将该模型应用于两个生化语料库并展示其有效性。 最后，我们开发了一个新颖的远程监督数据集，其中包含来自 PubM物-产物关系。 1ed 摘要的化学反应

## 2 提出的模型

我们将句间、文档级 RE 任务制定为分类问题。设 [w1, w2, · · · , wn] 是文档 t 中的词，e1 和 e2 是 t 中感兴趣的实体对。我们在文档实体提及中命名这些实体的多次出现。 关系提取模型将三元组 (e1, e2, t) 作为输入并返回该对的关系，包括“无关系”类别作为输出。 我们假设 t 中目标实体的关系可以根据它们的所有提及来推断。 因此，我们在 t 上应用多实例学习来组合所有提及级别对并预测目标对的最终关系类别。

我们在图 2 中描述了我们提出的模型的架构。该模型将科学文章的完整摘要和两个目标实体作为输入，并在输入层中提及它们。然后构建一个图结构，以单词为节点，标记边对应局部和非局部依赖。 接下来，它使用堆叠的 GCNN 层对图结构进行编码，并通过应用 MIL (Verga et al., 2018) 来聚合所有提及对表示来对目标实体之间的关系进行分类。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/GCNN/figure/figure_2.png)

图 2：提议的模型架构。 输入的词序列被映射到一个图结构，其中节点是词，边对应于依赖关系。 为简洁起见，我们省略了几个边，例如所有单词的自节点边和不同标签的句法依赖边。  GCNN 用于对图进行编码，双仿射层聚合所有提及对。

#### 2.1 输入层

在输入层，我们将每个单词 i 及其相对于第一个和第二个目标实体的位置分别映射到实值向量 wi、d1 i 、d2 i 中。由于实体可以有多个提及，我们从最近的目标实体提及计算一个词的相对位置。 对于每个单词 i，我们将单词和位置表示连接成一个输入表示，xi = [wi;  d1 ;  d2 ]。

#### 2.2 图结构

为了为整个摘要构建文档级图，我们使用以下类别的句间和句内依赖边，如图 2 中不同颜色所示。

**句法依赖边缘：**句子的句法结构揭示了句内 RE 的有用线索（Miwa 和 Bansal，2016 年）。 因此，我们通过将每个句法依赖标签视为不同的边缘类型，在每个句子的单词之间使用标记的句法依赖边缘。

**共指边：**由于共指是本地和非本地依赖关系的重要指标（Ma et al., 2016），我们使用共指类型边连接文档中的共指短语。

**相邻句子边缘：**我们将一个句子的句法词根与具有相邻句子类型边缘的前后句子的词根连接起来 (Peng et al., 2017)，用于相邻句子之间的非局部依赖。

**相邻词边缘：**为了保持句子的词之间的顺序信息，我们将每个词与其前一个和下一个词与相邻的词类型边缘连接起来。

**自节点边：**GCNN 仅根据其邻居节点及其边类型来学习节点表示。 因此，为了将节点信息本身包含在表示中，我们在图的所有节点上形成 selfnode 类型的边。

#### 2.3 GCNN层

我们通过在构建的文档图上应用 GCNN（Kipf 和 Welling，2017 年；Defferrard 等人，2016 年）来计算每个输入词 i 的表示。  GCNN 是用于图编码的 CNN 的高级版本，它学习图节点的语义表示，同时保留其结构信息。为了学习特定于边缘类型的表示，我们使用标记的边缘 GCNN，它为每种边缘类型保留单独的参数（Vashishth 等，2018）。GCNN 迭代更新每个输入词 i 的表示如下：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/GCNN/figure/formula_1.png)

其中 xk+1 i 是第 k 个 GCNN 块产生的第 i 个单词表示，ν(i) 是 i 的一组相邻节点，Wk l(i,u) 和 bk l(i,u) 是 节点 i 和 u 之间边类型 l 的第 k 个块的参数。 我们堆叠 K GCNN 块以积累来自远处相邻节点的信息，并使用边缘门控来控制来自相邻节点的信息。

与 Marcheggiani 和 Titov (2017) 类似，我们为每个边缘方向维护单独的参数。 然而，我们通过只为前 N 种类型保留单独的参数并对所有剩余的边类型使用相同的参数来调整模型参数的数量，称为“稀有”类型的边。 这可以避免由于不同边缘类型的过度参数化而可能导致的过度拟合。

#### 2.4 基于 MIL 的关系分类

由于每个目标实体在一个文档中可以有多个提及，我们采用基于多实例学习 (MIL) 的分类方案来使用双仿射成对评分聚合所有目标提及对的预测 (Verga et al., 2018)。如图 2 所示，首先使用两层前馈神经网络 (FFNN) 将每个单词 i 投影到两个单独的潜在空间中，这对应于目标对的第一个（头部）或第二个（尾部）参数。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/GCNN/figure/formula_2.png)

其中 xK i 对应于 |K| 之后的第 i 个单词的表示 GCNN 编码块，W(0), W(1) 分别是头和尾的两个 FFNN 的参数，xhead i , xtail i ∈ Rd 是第 i 个词的头/尾表示。

然后，提及级别的成对置信度分数由双仿射层生成并聚合以获得实体级别的成对分数。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/GCNN/figure/formula_3.png)

其中，R ∈ Rd×r×d 是一个学习的双仿射张量，r 是关系类别的数量，Ehead、Etail 分别表示实体 ehead 和 etail 的一组提及。

## 3 实验设置

我们首先简要描述了评估所提出模型及其预处理的数据集。 然后我们介绍用于比较的基线模型。 最后，我们展示了训练设置。

#### 3.1 数据集

我们在两个生物化学数据集上评估了我们的模型。

化学疾病关系数据集 (CDR)：CDR 数据集是为 BioCreative V 挑战开发的文档级、句间关系提取数据集 (Wei et al., 2015)。

化学反应数据集 (CHR)：我们使用远程监督创建了一个文档级数据集，其中包含化学品之间的关系。 首先，我们使用语义分面搜索引擎 Thalia2 (Soto et al., 2018) 的后端从 PubMed 获取用几个生物医学命名实体注释的摘要。 我们从带注释的实体中选择化合物，并将它们与图数据库 Biochem4j（Swainston 等，2017）对齐。  Biochem4j 是一个免费提供的数据库，它集成了 UniProt、KEGG 和 NCBI Taxonomy3 等多种资源。如果两个化学实体在 Biochem4j 中有关系，我们将它们视为数据集中的正实例，否则视为负实例。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/GCNN/figure/table_1.png)

表 1：CDR 和 CHR 数据集的统计数据。

#### 3.2 数据预处理

表 1 显示了 CDR 和 CHR 数据集的统计数据。对于这两个数据集，带注释的实体可以有多个关联的知识库 (KB) ID。 如果提及之间至少有一个公共知识库 ID，那么我们认为所有这些提及都属于同一实体。 这种技术导致更少的负对。我们忽略了未基于已知知识库 ID 的实体，并删除了同一实体之间的关系（自关系）。 对于 CDR 数据集，我们执行了类似于 Gu 等人的上位词过滤。 (2017) 和 Verga 等人。  (2018)。 在 CHR 数据集中，为每个候选化学对生成了两个方向，因为化学物质可以是相互作用中的反应物（第一个参数）或产物（第二个参数）。

我们分别使用 GENIA Sentence Splitter4 和 GENIA 标注器（Tsuruoka 等人，2005 年）处理数据集以进行句子分割和单词标记化。 使用具有谓词-参数结构的 Enju 句法解析器（Miyao 和 Tsujii，2008 年）获得句法依赖性。 使用斯坦福 CoreNLP 软件（Manning 等人，2014 年）构建了共指类型边。

#### 3.3 基准模型

对于 CDR 数据集，我们与五个最先进的模型进行比较：SVM（Xu 等人，2016b）、基于特征和神经的模型的集合（Zhou 等人，2016a）、CNN 和最大熵（  Gu 等人，2017）、分段 CNN（Li 等人，2018 年）和 Transformer（Verga 等人，2018 年）。 我们另外准备和评估以下模型：CNN-RE，Kim (2014) 和 Zhou 等人的重新实现。  (2016a) 和 RNN-RE，从 Sahu 和 Anand (2018) 重新实现。 在所有模型中，我们使用双仿射成对评分来检测关系。

#### 3.4 模型训练

我们使用了在 PubMed 和 GloVe 上训练的 100 维词嵌入（Pennington 等人，2014 年；TH 等人，2015 年）。 与 Verga 等人不同。  (2018)，我们使用预训练的词嵌入代替子词嵌入来与我们的词图对齐。 由于 CDR 数据集的大小，我们合并了训练集和开发集来训练模型，类似于 Xu 等人。  (2016a) 和顾等人。  (2017)。 我们将性能报告为在精度 (P)、召回率 (R) 和 F1 分数方面使用不同参数初始化种子的五次运行的平均值。 我们使用训练集中边缘类型的频率来选择第 2.3 节中的前 N 个边缘。 我们参考补充材料了解训练和超参数设置的详细信息。

## 4 结论

我们在表 2 中展示了我们的 CDR 和 CHR 数据集模型的结果。我们报告了没有任何额外增强的最先进模型的性能，例如与 NER 的联合训练、模型集成和启发式规则，以避免 比较中增强的任何影响。 我们观察到 GCNN 在两个数据集中都优于基线模型 (CNN-RE/RNN-RE)。 然而，在 CDR 数据集中，GCNN 的性能比 (Gu et al., 2017) 的最佳性能系统低 1.6 个百分点。 事实上，顾等人。  (2017) 分别为句内和句间对合并了两个独立的神经模型和基于特征的模型，而我们对两个对都使用了一个模型。此外，GCNN 的性能与 Li 等人的第二个最先进的神经模型相当。  (2018)，与我们的统一方法不同，它需要一个两步过程来进行提及聚合。

图 3 说明了我们的模型在使用不同数量的最常见边缘类型 N 时在 CDR 开发集上的性能。在调整 N 时，我们观察到 top-4 边缘类型获得了最佳性能，但性能稍有下降。 我们在其他实验中选择了 top-4 边缘类型。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/GCNN/figure/table_2.png)

表 2：与最先进技术相比，CDR 和 CHR 测试集的性能。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/GCNN/figure/figure_3.png)

图 3：GCNN 模型在 CDR 开发集上的性能，当使用 top-N 最常见的边缘类型并将其余的视为单个“稀有”类型时。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/GCNN/figure/table_3.png)

表 3：对 CDR 开发集的消融分析，以 F1 分数 (%) 表示，用于句内 (Intra) 和句间 (Inter) 对。

我们通过将开发集分离为句内和句间对（分别约为 70% 和 30%）对 CDR 数据集进行消融分析。表 3 显示了一次删除一个边缘类别时的性能。 总的来说，所有依赖类型对句间 RE 和整体性能都有积极影响，尽管自节点和相邻句子边缘对句内关系的性能略有损害。 此外，共指不影响句内对。

## 5 相关工作

Inter-sentence RE 是最近引入的任务。彭等人。  (2017) 和宋等人。  (2018) 在蛋白质-药物-疾病关联的多个句子中使用基于图的 LSTM 网络进行 n-ary RE。 他们将关系候选者限制在最多两个跨度的句子中。 维尔加等人。  (2018) 考虑了文档级 RE 的多实例学习。 我们的工作与 Verga 等人不同。  (2018) 中，我们用 GCNN 模型替换 Transformer，使用非局部依赖项（如实体共指）进行全抽象编码。

GCNN 最早由 Kipf 和 Welling (2017) 提出，并应用于引文网络和知识图数据集。 它后来被用于语义角色标记（Marcheggiani 和 Titov，2017 年）、多文档摘要（Yasunaga 等人，2017 年）和时间关系提取（Vashishth 等人，2018 年）。 张等人。  (2018) 在依赖树上使用 GCNN 用于句内 RE。 与之前的工作不同，我们在文档级图上引入了 GCNN，对句间 RE 具有句内和句间依赖性。

## 6 总结

我们提出了一种新的基于图的方法，在文档级图上使用标记的边缘 GCNN 模型进行句间 RE。该图以单词为节点，以它们之间的多个句内和句间依赖关系为边构建。 使用 GCNN 模型对图结构进行编码，并结合 MIL 来聚合多个提及级别对。 我们表明，我们的方法在两个生物化学数据集上实现了与最先进的神经模型相当的性能。 我们调整了标记边缘的数量以保持标记边缘 GCNN 中的参数数量。 分析表明，所有边缘类型都对句间 RE 有效。

尽管该模型应用于句间 RE 的生化语料库，但我们的方法也适用于其他关系提取任务。 作为未来的工作，我们计划结合联合命名实体识别训练以及子词嵌入，以进一步提高所提出模型的性能。























