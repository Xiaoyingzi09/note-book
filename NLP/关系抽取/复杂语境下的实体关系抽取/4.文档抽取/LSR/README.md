# 用于文档级关系提取的潜在结构细化推理

# Reasoning with Latent Structure Refinement for Document-Level Relation Extraction

## 摘要

文档级关系提取需要在文档的多个句子内部和之间集成信息，并捕获句子间实体之间的复杂交互。然而，文档中相关信息的有效聚合仍然是一个具有挑战性的研究问题。现有方法基于来自非结构化文本的句法树、共同引用或启发式构建静态文档级图，以对依赖项进行建模。与之前的方法可能无法捕获丰富的非局部交互进行推理不同，我们提出了一种新颖的模型，该模型通过自动引入潜在文档级图来增强句子之间的关系推理。 我们进一步开发了一种细化策略，使模型能够增量聚合相关信息以进行多跳推理。 具体来说，我们的模型在大规模文档级数据集 (DocRED) 上获得了 59.05 的 F1 分数，比之前的结果显着提高，并且还在 CDR 和 GDA 数据集上产生了最新的最新结果。 此外，广泛的分析表明该模型能够发现更准确的句子间关系。

## 1 前言

关系抽取旨在检测文本中实体之间的关系，在各种自然语言处理应用中发挥着重要作用。 早期的研究工作侧重于预测句子中实体之间的关系（Zeng et al., 2014; Xu et al., 2015a,b）。 然而，实体之间有价值的关系信息，例如生物医学发现，是通过在现实世界场景中跨越句子边界的多次提及来表达的（Peng 等，2017）。 因此，生物医学领域的提取范围最近已扩展到跨句子级别（Quirk and Poon, 2017; Gupta et al., 2018; Song et al., 2019）。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/LSR/figure/figure_1.png)

图 1：改编自 DocRED 数据集的示例。 该示例有四个实体：Lutsenko、内部事务、Yulia Tymoshenko 和乌克兰人。 此处实体 Lutsenko 有两个提及：Lutsenko 和 He。 与同一实体对应的提及用相同的颜色突出显示。 实线和虚线分别代表句内和句间关系。

一个更具挑战性但实用的扩展是文档级关系提取，其中系统需要理解多个句子，通过综合整个文档中的相关信息来推断实体之间的关系（Jia 等人，2019 年；Yao 等人，2019 年）。  , 2019)。 图 1 显示了一个改编自最近提出的文档级数据集 DocRED（Yao 等人，2019）的示例。为了推断尤利娅·季莫申科和乌克兰人之间的句子间关系（即国籍国），首先必须确定卢岑科与尤利娅·季莫申科合作的事实。 接下来我们确定 Lutsenko 管理内部事务，这是一个乌克兰当局。 在逐步连接文档中的证据并执行逐步推理后，我们可以推断尤利娅·季莫申科也是乌克兰人。

先前的努力表明，实体提及之间的交互促进了文档级关系提取中的推理过程。 因此，Verga 等人。  (2018) 和贾等人。  (2019) 利用多实例学习（Riedel 等人，2010 年；Surdeanu arXiv:2005.06312v3 [cs.CL] 2020 年 7 月 28 日等人，2012 年）。 另一方面，结构信息已被用于执行更好的推理，因为它对仅从表面形式模糊的非局部依赖性进行建模。 彭等人。(2017) 构建依赖图来捕获 n-ary 实体之间的交互以进行交叉句子提取。 萨胡等人。  (2019) 通过使用共同引用链接连接句子的依赖树来构建文档级图来扩展这种方法。 相反，克里斯托普卢等人。  (2019) 基于一组启发式构建异构图，然后应用面向边缘的模型 (Christopoulou et al., 2018) 进行推理。

与以前的方法不同，文档级结构是由共同引用和规则构建的，我们提出的模型将图结构视为潜在变量，并以端到端的方式引入它。 我们的模型是基于结构化注意力构建的（Kim 等，2017；Liu 和 Lapata，2018）。 使用矩阵树定理的变体（Tutte，1984；Koo 等，2007），我们的模型能够生成特定于任务的依赖结构，用于捕获实体之间的非局部交互。我们进一步开发了迭代细化策略，使我们的模型能够基于上次迭代动态构建潜在结构，从而使模型能够增量捕获复杂的交互，以实现更好的多跳推理（Welbl 等人，2018 年）。

实验表明，我们的模型在 DocRED 上明显优于现有方法，DocRED 是一个具有大量实体和关系的大规模文档级关系提取数据集，并且还在两个流行的文档级上产生了新的最先进的结果 生物医学领域的关系提取数据集。 代码和预训练模型可在 https://github.com/nanguoshun/LSR 1 获得。

我们的贡献总结如下：

- 我们以端到端的方式构建用于推理的文档级图，而不依赖于可能并不总是产生最佳结构的共同引用或规则。 通过迭代细化策略，我们的模型能够动态构建潜在结构，以改进整个文档中的信息聚合。
- 我们进行定量和定性分析，以与各种设置中的最先进模型进行比较。 我们证明我们的模型能够通过利用多跳推理模块发现更准确的句子间关系。



## 2 模型

在本节中，我们提出了用于文档级关系提取任务的潜在结构细化（LSR）模型。 我们的 LSR 模型由三个组件组成：节点构造函数、动态推理器和分类器。 节点构造器首先对输入文档的每个句子进行编码并输出上下文表示。与句子中最短依赖路径上的提及和标记相对应的表示被提取为节点。 然后应用动态推理器根据提取的节点归纳出文档级结构。 节点的表示根据潜在结构上的信息传播进行更新，该结构是迭代细化的。 节点的最终表示用于计算分类器的分类分数。

#### 2.1 节点构造器

节点构造函数将文档中的句子编码为上下文表示，并构造提及节点、实体节点和元依赖路径（MDP）节点的表示，如图 2 所示。这里 MDP 表示句子中所有提及的最短依赖路径集，  MDP中的token被提取为MDP节点。

##### 2.1.1 上下文编码

给定一个文档 d，其中的每个句子 di 都被馈送到上下文编码器，它输出 di 中每个单词的上下文化表示。 上下文编码器可以是双向 LSTM (BiLSTM)（Schuster 和 Paliwal，1997）或 BERT（Devlin 等，2019）。 这里我们以 BiLSTM 为例：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/LSR/figure/formula_1.png)

其中 ←− hi j, ←− hij+1, −→ hi j 和 −→ hij−1 表示句子中第 j 个、第 (j+1) 个和第 (j-1) 个标记的隐藏表示 两个方向的di，γi j 表示第j个token的词嵌入。 句子中每个标记的上下文表示表示为 hi j = [ ←− hi j;  −→ hi j] 通过连接两个方向的隐藏状态，其中 hi j ∈ Rd 和 d 是维度。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/LSR/figure/figure_2.png)

图 2：节点构造器概述：应用上下文编码器来获取句子的上下文化表示。 元依赖路径中提及和单词的表示被提取为提及节点和 MDP 节点。 平均池化用于从提及节点构建实体节点。 例如，实体节点 Lutsenko 是通过对其提及 Lutsenko 和 He 的表示求平均来构建的。所有数字最好用彩色查看。

##### 2.1.2 节点提取

我们为文档级图构建了三种类型的节点：提及节点、实体节点和元依赖路径（MDP）节点，如图 2 所示。提及节点对应于每个句子中实体的不同提及。 实体节点的表示被计算为其提及的平均值。 为了构建文档级图，现有方法使用句子依赖树中的所有节点 (Sahu et al., 2019) 或通过对句子的所有标记表示求平均值来使用一个句子级节点 (Christopoulou et al., 2019)  . 或者，我们在句子中提及之间的最短依赖路径上使用标记。 最短依赖路径在句子级关系提取中被广泛使用，因为它能够有效地利用相关信息而忽略不相关信息（Bunescu and Mooney, 2005; Xu et al., 2015a,b）。与句子级提取每个句子只有两个实体不同，这里的每个句子可能涉及多个提及。

#### 2.2 动态推理器

动态推理器有两个模块，结构归纳和多跳推理，如图 3 所示。结构归纳模块用于学习文档级图的潜在结构。多跳推理模块用于对诱导的潜在结构进行推理，其中每个节点的表示将根据信息聚合方案进行更新。 我们堆叠 N 个块以迭代地优化潜在文档级图以进行更好的推理。

##### 2.2.1 结构归纳

与使用共同引用链接（Sahu 等人，2019 年）或启发式（Christopoulou 等人，2019 年）构建文档级图进行推理的现有模型不同，我们的模型将图视为潜在变量并将其归纳为 一种端到端的时尚。结构归纳模块是基于结构化注意力构建的（Kim 等，2017；Liu 和 Lapata，2018）。 受 Liu 和 Lapata (2018) 的启发，我们使用 Kirchhoff 矩阵树定理 (Tutte, 1984; Koo et al., 2007) 的变体来诱导潜在依赖结构。

让 ui 表示第 i 个节点的上下文表示，其中 ui ∈ Rd，我们首先使用节点表示 ui 和 uj 计算第 i 个节点和第 j 个节点之间的成对非归一化注意力分数 sij。 分数 sij 由两个前馈神经网络和一个双线性变换计算：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/LSR/figure/formula_2.png)

其中 Wp ∈ Rd×d 和 Wc ∈ Rd×d 是两个前馈神经网络的权重，d 是节点表示的维度，tanh 用作激活函数。  Wb ∈ Rd×d 是双线性变换的权重。 接下来，我们计算根分数 sr i，它表示要选择作为结构根节点的第 i 个节点的非归一化概率：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/LSR/figure/formula_3.png)

其中 Wr ∈ R1×d 是线性变换的权重。 继 Koo 等人之后。  (2007)，我们计算文档级图的每个依赖边的边际概率。 对于具有 n 个节点的图 G，我们首先为图的边分配非负权重 P ∈ Rn×n：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/LSR/figure/formula_4.png)

其中 Pij 是第 i 个节点和第 j 个节点之间的边的权重。 然后，我们在等式（6）中定义 G 的拉普拉斯矩阵 L ∈ Rn×n，在等式（7）中定义其变体 ˆL ∈ Rn×n 用于进一步计算（Koo 等人，2007）。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/LSR/figure/formula_5.png)

我们用 Aij 表示第 i 个节点和第 j 个节点之间的依赖边的边际概率。 然后，可以根据等式 (8) 推导出 Aij，其中 δ 是 Kronecker delta（Koo 等人，2007 年）。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/LSR/figure/formula_6.png)

这里，A ∈ Rn×n 可以解释为文档级实体图的加权邻接矩阵。 最后，我们可以将 A ∈ Rn×n 输入多跳推理模块以更新潜在结构中节点的表示。

##### 2.2.2 多跳推理

图神经网络已被广泛用于执行多跳推理的不同任务（Song 等人，2018a；Yang 等人，2019 年；Tu 等人，2019 年；Lin 等人，2019 年），因为它们能够 基于信息聚合方案有效收集相关证据。 具体来说，我们的模型基于图卷积网络 (GCN)（Kipf 和 Welling，2017 年）来执行推理。

形式上，给定一个有 n 个节点的图 G，它可以用一个 n × n 邻接矩阵 A 来表示，该矩阵由前面的结构归纳模块归纳，第 l 层节点 i 的卷积计算，其表示为 ul−  1 i 来自前一层作为输入并输出更新后的表示 ul i，可以定义为：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/LSR/figure/formula_7.png)

其中 Wl 和 bl 分别是第 l 层的权重矩阵和偏置向量。  σ 是 ReLU（Nair 和 Hinton，2010）激活函数。  u0 i ∈ Rd 是节点构造函数构造的第 i 个节点的初始上下文表示。

继郭等人。  (2019b)，我们使用与 GCN 的密集连接，以便在大型文档级图上捕获更多结构信息。 在密集连接的帮助下，我们能够训练更深层次的模型，允许捕获更丰富的本地和非本地信息，以学习更好的图形表示。 每个图卷积层的计算类似于等式（9）。

##### 2.2.3 迭代细化

尽管结构化注意力（Kim 等人，2017 年；Liu 和 Lapata，2018 年）能够自动诱导潜在结构，但最近的研究工作表明，诱导结构相对较浅，可能无法对复杂的文档依赖关系建模—— 水平输入（Liu 等人，2019b；Ferracane 等人，2019 年）。 与之前的工作（Liu 和 Lapata，2018）只诱导一次潜在结构不同，我们根据更新的表示反复细化文档级图，使模型能够推断出更多信息的结构，而不仅仅是简单的父子关系。

如图 3 所示，我们将动态推理器的 N 块堆叠起来，以将文档级结构归纳为 N 次。 直观地，推理器在早期迭代中引入了一个浅层结构，因为信息主要在相邻节点之间传播。 随着结构通过与更丰富的非局部信息的交互而变得更加精细，归纳模块能够生成更多信息的结构。

#### 2.3 分类器

经过 N 次细化，我们获得了所有节点的表示。 继姚等人。  (2019)，对于每个实体对 (ei, ej)，我们使用双线性函数来计算每个关系类型 r 的概率为：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/LSR/figure/formula_8.png)

其中 We ∈ Rd×k×d 和 be ∈ Rk 是可训练的权重和偏差，k 是关系类别的数量，σ 是 sigmoid 函数，等式右侧的下标 r 是指关系类型。

## 3 实验

#### 3.1 数据

我们在 DocRED（Yao 等人，2019 年）上评估我们的模型，DocRED 是用于文档级关系提取的最大人工注释数据集，以及生物医学领域另外两个流行的文档级关系提取数据集，包括化学疾病反应（CDR）（  Li 等人，2016a) 和基因疾病协会 (GDA)（Wu 等人，2019 年）。  DocRED 包含 3, 053 个用于训练的文档，1, 000 个用于开发和 1, 000 个用于测试，总共有 132, 375 个实体和 56, 354 个关系事实。  CDR由500个训练实例、500个开发实例和500个测试实例组成。GDA 包含 29, 192 个用于训练的文档和 1, 000 个用于测试的文档。 我们遵循 (Christopoulou et al., 2019) 将 GDA 的训练集拆分为 80/20 的拆分用于训练和开发。

由于超过 40% 的关系事实需要对多个句子进行阅读和推理，DocRED 与之前的句子级数据集有显着不同（Doddington 等人，2004 年；Hendrickx 等人，2009 年；Zhang 等人，2018 年）。 与现有的文档级数据集（Li et al., 2016a; Quirk and Poon, 2017; Peng et al., 2017; Verga et al., 2018; Jia et al., 2019）不同，这些数据集在特定的生物医学领域仅考虑 药物-遗传病关系，DocRED 涵盖了广泛的类别，具有 96 种关系类型。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/LSR/figure/table_1.png)

表 1：LSR 的超参数。

#### 3.2 设置

我们使用 spaCy2 来获取文档中句子的元依赖路径。 继姚等人。(2019) 和 Wang 等人。  （2019 年），我们使用 GloVe（Pennington 等人，2014 年）嵌入 BiLSTM，以及 Uncased BERT-Base（Devlin 等人，2019 年）作为上下文编码器。所有超参数都根据开发集进行调整。 我们在表 1 中列出了一些重要的超参数。

继姚等人。  (2019)，我们使用 F1 和 Ign F1 作为评估指标。  Ign F1 表示 F1 分数，不包括训练集和开发/测试集共享的关系事实。 还报告了句内和句间实体对的 F1 分数。 测试集的评估是通过 CodaLab3 完成的。

#### 3.3 主要结果

我们在 DocRED 数据集上将我们提出的 LSR 与以下三种竞争模型进行比较，并在表 2 中显示了主要结果。

- 基于序列的模型。这些模型利用不同的神经架构对文档中的句子进行编码，包括卷积神经网络 (CNN) (Zeng et al., 2014)、LSTM、双向 LSTM (BiLSTM) (Cai et al., 2016) 和基于注意力的 LSTM (  ContextAware）（Sorokin 和 Gurevych，2017 年）。
- 基于图的模型。这些模型构建特定任务的推理图。  GCNN (Sahu et al., 2019) 通过共同引用链接构建文档级图，然后应用关系 GCN 进行推理。  EoG (Christopoulou et al., 2019) 是生物医学领域最先进的文档级关系提取模型。EoG 首先使用启发式方法构建图，然后利用面向边缘的模型进行推理。  GCNN 和 EoG 基于静态结构。  GAT (Veliˇckovi´c et al., 2018) 能够基于局部注意力机制学习加权图结构。  AGGCN (Guo et al., 2019a) 是最先进的句子级关系提取模型，它通过自注意力构建潜在结构。 这两个模型能够动态构建特定于任务的结构。
- 基于 BERT 的模型。这些模型为 DocRED 微调了 BERT（Devlin 等人，2019 年）。 具体而言，两阶段 BERT（Wang 等人，2019 年）是报告最好的模型。 它是一个管道模型，它在第一阶段预测实体对之间是否存在关系，并在第二阶段预测关系的类型。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/LSR/figure/table_2.png)

如表 2 所示，带有 GloVe 的 LSR 在测试集上达到了 54.18 F1，这是带有 GloVe 的模型的最新最新结果。 特别是，我们的模型始终以显着优势优于基于序列的模型。 例如，LSR 在 F1 方面比最佳的基于序列的模型 BiLSTM 提高了 3.1 个点。 这表明直接编码整个文档的模型无法捕获文档中存在的句间关系。

在相同的设置下，我们的模型始终优于基于静态图或注意力机制的基于图的模型。 与 EoG 相比，我们的 LSR 模型在开发和测试集上的 F1 分别提高了 3.0 和 2.4。 我们对 GCNN 模型也有类似的观察结果，这表明静态文档级图可能无法捕获文档中的复杂交互。  LSR 诱导的动态潜在结构捕获了更丰富的非局部依赖性。 此外，LSR 也优于 GAT 和 AGGCN。 这从经验上表明，与使用局部注意和自我注意的模型（Veliˇckovi´c 等人，2018 年；Guo 等人，2019a）相比，LSR 可以诱导更多信息性文档级结构以进行更好的推理。 我们的 LSR 模型在 Ign F1 的设置下也显示了它的优越性。

此外，LSR with GloVe 比两个基于 BERT 的模型获得了更好的结果。 这凭经验表明，即使不使用强大的上下文编码器，我们的模型也能够捕获远程依赖关系。 继王等人。  (2019)，我们利用 BERT 作为上下文编码器。 如表 2 所示，我们使用 BERT 的 LSR 模型在 DocRED 上获得了 59.05 F1 分数，这是一个新的最先进的结果。 截至 2019 年 12 月 9 日的 ACL 截止日期，我们以别名 diskorak 的名义在 CodaLab 记分牌上保持第一名。

#### 3.4 句内和句间表现

在本小节中，我们分析了开发集上的句内和句间性能。 如果来自同一文档的两个实体在同一句子中没有提及，则实体对需要句子间推理。 在 DocRED 的开发集中，大约 45% 的实体对需要对多个句子进行信息聚合。

在相同的设置下，我们的 LSR 模型在句内和句间设置中都优于所有其他模型。  LSR 与其他模型在句间设置中 F1 分数的差异往往大于句内设置中的差异。 这些结果表明 LSR 的大部分优势来自句间关系事实，这表明我们的模型诱导的潜在结构确实能够跨文档的多个句子综合信息。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/LSR/figure/table_3.png)

表 3：CDR 数据集测试集的结果。 双线下方的方法利用额外的训练数据和/或结合外部工具。

此外，与两个基于 BERT (Wang et al., 2019) 的模型相比，带有 GloVe 的 LSR 在句间设置方面也被证明更好，这表明与 BERT 编码器相比，潜在结构在解决整个文档的长程依赖性方面具有优势。

#### 3.5 生物医学数据集的结果

表 3 描述了与最先进模型在 CDR 数据集上的比较。顾等人。(2017);  Nguyen 和 Verspoor (2018)； 维尔加等人。 (2018) 利用基于序列的模型。 卷积神经网络和自注意力网络用作编码器。萨胡等人。  (2019); 克里斯托普卢等人。  (2019) 使用基于图的模型。 如表 3 所示，我们的 LSR 的性能比最先进的模型差。 现成的解析器很难在生物医学领域获得高质量的依赖树，因为我们观察到，与来自 DocRED 的节点相比，spaCy 解析器从 CDR 数据集中提取的 MDP 节点包含的信息上下文要少得多。 在这里，我们引入了一个简化的 LSR 模型，表示为“LSR w/o MDP Nodes”，它移除了 MDP 节点并使用文档的所有标记构建了一个完全连接的图。它表明“LSR w/o MDP Nodes”始终优于基于序列和基于图的模型，表明潜在结构的有效性。 此外，简化的 LSR 优于大多数具有外部资源的模型，除了 Li 等人。  (2016b)，它利用联合训练和额外的未标记训练数据。 我们相信这样的设置也有利于我们的 LSR 模型。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/LSR/figure/table_4.png)

表 4：GDA 数据集测试集的结果。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/LSR/figure/figure_4.png)

图 4：QAGCN、EoG、AGGCN 和 LSR 中不同图结构的句内和句间 F1。细化的数量从 1 到 4 不等。

表 4 显示了远程监督 GDA 数据集的结果。 这里“Full”表示以全连接图作为输入的 EoG 模型，而“NoInf”是没有推理组件的 EoG 模型的变体（Christopoulou et al., 2018）。 简化的 LSR 模型在 GDA 上实现了最新的最新结果。  “完整”模型（Christopoulou 等人，2019 年）在句间设置上产生更高的 F1 分数，而在句内设置上的分数相对较低。 这可能是因为该模型忽略了句子内和句子间表达的关系之间的差异。

#### 3.6 模型分析

在本小节中，我们使用 DocRED 的开发集来演示潜在结构和改进的有效性。

##### 3.6.1 潜在结构重要吗？

我们研究了由提议的动态推理器诱导和迭代改进的潜在结构在多大程度上有助于提高整体性能。 我们用下面定义的三种不同结构进行试验。 为了公平比较，我们使用相同的 GCN 模型对所有这些结构执行多跳推理。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/LSR/figure/figure_5.png)

图 5：DocRED 开发集示例的案例研究。 我们将 LSR 和 AGGCN 预测实体对 ⟨Japan, World War II⟩ 关系的推理过程可视化，分两个细化步骤，在每个步骤中使用提及 World War II 的注意力分数。 我们将所有注意力分数按 1000 进行缩放以更清楚地说明它们。 限于篇幅，部分句子省略。

基于规则的结构：我们在 EoG 中使用基于规则的结构（Christopoulou 等，2019）。 此外，我们采用了 De Cao 等人的规则。  （2019）对于多跳问答，即每个提及节点都连接到它的实体节点和跨句子的相同提及节点，而位于同一句子中的提及节点和 MDP 节点是完全连接的。 该模型称为 QAGCN。

基于注意力的结构：该结构由具有多头注意力的 AGGCN（Guo 等人，2019a）诱导（Vaswani 等人，2017 年）。 我们将模型从句子级扩展到文档级。

我们探索了这些模型的多个设置，具有从 1 到 4 的不同块编号，其中一个块由图构建组件和密集连接的 GCN 组件组成。 如图 4 所示，LSR 在整体 F1 方面优于 QAGCN、EoG 和 AGGCN。这从经验上证实了我们的假设，即由 LSR 诱导的潜在结构能够为整个文档捕获更多信息上下文。

##### 3.6.2 细化重要吗？

如图 4 所示，我们的 LSR 在第二次改进中产生了最佳性能，在整体 F1 方面比第一次归纳高 0.72%。 这表明所提出的 LSR 能够通过迭代细化产生更准确的结构。 但是，过多的迭代可能会由于过拟合而导致 F1 下降。

#### 3.7 消融研究

表 5 显示了完整 LSR 模型的 F1 分数，并且一次关闭一个不同的组件。 我们观察到大多数组件都对主模型有贡献，因为缺少任何组件都会导致性能下降。最显着的差异体现在结构归纳模块中。 去除结构诱导部分导致F1分数下降3.26。 该结果表明潜在结构在整体性能中起着关键作用。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/LSR/figure/table_5.png)

#### 3.8 案例分析

在图 5 中，我们提出了一个案例研究来分析为什么我们提出的 LSR 诱导的潜在结构比 AGGCN 学习的结构表现更好。 我们使用实体 World War II 来说明推理过程，我们的目标是预测实体对 ⟨Japan, World War II⟩ 的关系。 如图 5 所示，在 LSR 的第一次细化中，Word War II 与几个具有较高注意力得分的本地提及进行交互，例如提及 Lake Force 为 0.30，这将用作提及日本和第二次世界大战之间的桥梁 . 在第二个细化中，日本和日本帝国陆军等几个非本地提及的注意力分数分别从 0.09 显着增加到 0.41 和 0.17 到 0.37，表明信息在这一步是在全球传播的。 有了这样的句内和句间结构，实体对⟨Japan, World War II⟩的关系可以预测为“participant of”，用P1344表示。 与LSR相比，AGGCN学习到的注意力分数要平衡得多，说明该模型可能无法构建用于推理的信息结构，例如，第二个头部的最高分数为0.27，大部分分数接近 0.11。

我们还在图 5 右侧的图形上描绘了 ContextAware、AGGCN 和 LSR 的预测关系。 有兴趣的读者可以参考（Yao et al., 2019）关于关系的定义，例如 P607、P17、  LSR 模型证明能够填补 ⟨Japan, World War II⟩ 需要跨句子推理的缺失关系。 然而，LSR 也关注到了高分的提及新爱尔兰，因此未能预测实体对 ⟨New Ireland, World War II⟩ 实际上没有关系（NIL 类型）。

## 4 相关工作

文档级关系抽取。早期的努力侧重于通过对输入序列中的交互进行建模来预测单个句子中实体之间的关系（Zeng 等，2014；Wang 等，2016；Zhou 等，2016；Zhang 等，2017；Guo 等）  al., 2020) 或相应的依赖树（Xu et al., 2015a,b; Liu et al., 2015; Miwa and Bansal, 2016; Zhang et al., 2018）。 这些方法不考虑提及之间的交互，并忽略跨句子边界表达的关系。 最近的工作开始探索交叉句子提取（Quirk 和 Poon，2017；Peng 等，2017；Gupta 等，2018；Song 等，2018c，2019）。 这些方法没有使用话语结构理解技术（Liu et al., 2019a; Lei et al., 2017, 2018），而是利用依赖图来捕捉句子间的交互，并且它们的范围仍然限于几个句子。 最近，提取范围已扩展到整个文档（Verga et al., 2018; Jia et al., 2019; Sahu et al., 2019; Christopoulou et al., 2019），只考虑一个 化学品之间的关系很少。 与之前的工作不同，我们专注于来自不同领域的文档级关系提取数据集（Yao et al., 2019; Li et al., 2016a; Wu et al., 2019），具有大量关系和实体，需要理解 一个文档并执行多跳推理。

基于结构的关系推理。结构信息已广泛用于各种 NLP 应用程序中的关系推理，包括问答（Dhingra 等人，2018 年；De Cao 等人，2019 年；Song 等人，2018a）和关系提取（Sahu 等人，2019 年；  Christopoulou 等人，2019 年）。 宋等人。  (2018a) 和 (De Cao et al., 2019) 利用共同参考信息和规则集来构建文档级实体图。
   GCN（Kipf 和 Welling，2017）或 GRN（Song 等，2018b）用于执行多跳问答推理（Welbl 等，2018）。
 萨胡等人。  (2019) 还利用共同引用链接构建依赖图，并使用标记的边 GCN（Marcheggiani 和 Titov，2017）进行文档级关系提取。  Christopoulou 等人没有使用 GNNs。  (2019) 使用面向边缘的模型 (Christopoulou et al., 2018) 基于启发式构建的异构图进行逻辑推理。 与之前使用句法树、共同引用或启发式方法的方法不同，LSR 模型将文档级结构视为潜在变量，并以迭代细化的方式将其引入，从而允许模型动态构建图以进行更好的关系推理。

## 5 总结

我们引入了一种新的潜在结构细化 (LSR) 模型，以便在文档级关系提取任务中更好地推理。 与之前依赖句法树、共同引用或启发式的方法不同，LSR 动态地学习文档级结构并以端到端的方式进行预测。 未来的工作有多种途径。 一种可能的方向是在不依赖外部解析器的情况下扩展节点构造的结构归纳范围。















