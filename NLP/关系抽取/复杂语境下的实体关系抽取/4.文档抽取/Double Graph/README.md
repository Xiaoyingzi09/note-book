# Double Graph Based Reasoning for Document-level Relation Extraction

# 基于双图的文档级关系抽取推理

## 摘要

文档级关系提取旨在提取文档内实体之间的关系。 与句子级关系提取不同，它需要对文档中的多个句子进行推理。在本文中，我们提出了具有双图特征的图聚合和推理网络（GAIN）。  GAIN 首先构建一个异构的提及级别图 (hMG) 来模拟文档中不同提及之间的复杂交互。它还构建了一个实体级图（EG），在此基础上我们提出了一种新的路径推理机制来推断实体之间的关系。 在公共数据集 DocRED 上的实验表明，与之前的最新技术相比，GAIN 实现了显着的性能提升（F1 上的 2.85）。 我们的代码可从 https://github.com/DreamInvoker/GAIN 获得。

## 1 前言

从文本中识别实体之间的语义关系的任务，即关系提取 (RE)，在各种基于知识的应用中起着至关重要的作用，例如问答 (Yu et al., 2017) 和大规模知识图谱构建 . 以前的方法（Zeng et al., 2014; Zeng et al., 2015; Xiao and Liu, 2016; Zhang et al., 2017; Zhang et al., 2018; Baldini Soares et al., 2019）侧重于句子级别 RE，在单个句子中预测实体之间的关系。 然而，句子级 RE 模型有一个不可避免的局限性——它们无法识别句子间实体之间的关系。 因此，在文档级别提取关系对于全面理解文本知识是必要的。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/b35d161a9a6df59dc34edc8b878522fbea77f5f2/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/Double%20Graph/figure/figure_1.png)

图 1：来自 DocRED 的示例文档及其所需的关系（Yao 等，2019）。 这些关系实例中涉及的实体提及和关系是彩色的。 为清楚起见，其他提及的内容都标有下划线。

在文档级别进行有效的关系提取有几个主要挑战。 首先，关系中涉及的主宾实体可能出现在不同的句子中。 因此，不能仅基于单个句子来识别关系。 其次，同一实体可能在不同的句子中被多次提及。 必须聚合跨句上下文信息以更好地表示实体。 第三，许多关系的识别需要逻辑推理技术。 这意味着只有当其他实体和关系（通常分布在句子中）被隐式或显式识别时，才能成功提取这些关系。 如图1所示，很容易识别句内关系（马里兰州，国家，美国），（巴尔的摩，位于行政领土实体，马里兰州），和（埃尔德斯堡，位于行政领土实体，马里兰州）， 因为主语和宾语出现在同一个句子中。 然而，预测巴尔的摩和美国之间以及埃尔德斯堡和美国之间的句间关系并非易事，它们的提及不会出现在同一个句子中并且具有长距离依赖关系。 此外，这两个关系实例的识别也需要逻辑推理。 例如，埃尔德斯堡属于美国，因为埃尔德斯堡位于属于美国的马里兰州。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/b35d161a9a6df59dc34edc8b878522fbea77f5f2/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/Double%20Graph/figure/table_1.png)

表 1：从用于 BiLSTM 的 DocRED 开发集（Yao et al., 2019）随机抽样的 100 个文档中的坏案例统计，总共有 1150 个坏案例。

最近，姚等人。  (2019) 提出了一个大规模人工注释的文档级 RE 数据集 DocRED，将句子级 RE 推进到文档级，它包含大量的关系事实。 图 1 显示了来自 DocRED 的示例。我们从 DocRED 开发集中随机抽取 100 个文档，并手动分析由 Yao 等人提出的基于 BiLSTM 的模型预测的坏案例。  (2019)。 如表 1 所示，句间错误类型和逻辑推理错误类型在所有坏案例中占很大比例，分别为 53.5% 和 21.0%。 因此，在本文中，我们旨在解决这些问题，以更好地从文档中提取关系。最近，姚等人。  (2019) 提出了一个大规模人工注释的文档级 RE 数据集 DocRED，将句子级 RE 推进到文档级，它包含大量的关系事实。 图 1 显示了来自 DocRED 的示例。我们从 DocRED 开发集中随机抽取 100 个文档，并手动分析由 Yao 等人提出的基于 BiLSTM 的模型预测的坏案例。  (2019)。 如表 1 所示，句间错误类型和逻辑推理错误类型在所有坏案例中占很大比例，分别为 53.5% 和 21.0%。 因此，在本文中，我们旨在解决这些问题，以更好地从文档中提取关系。

以前在文档级 RE 中的工作不考虑推理（Gupta 等人，2019 年；Jia 等人，2019 年；Yao 等人，2019 年），或仅使用基于图的或分层神经网络在隐式中进行推理 (Peng et al., 2017; Sahu et al., 2019; Nan et al., 2020)。 在本文中，我们提出了一种用于文档级关系提取的图聚合和推理网络（GAIN）。 它旨在直接解决上述挑战。  GAIN 构建了一个异构的提及级图（hMG），具有两种类型的节点，即提及节点和文档节点，以及三种不同类型的边，即实体内边、实体间边和文档边，以捕获上下文 文档中实体的信息。 然后，我们在 hMG 上应用 Graph Convolutional Network（Kipf 和 Welling，2017）以获得每个提及的文档感知表示。然后通过合并引用 hMG 中相同实体的提及来构建实体级图（EG），在此基础上我们提出了一种新的路径推理机制。 这种推理机制允许我们的模型推断实体之间的多跳关系。

总之，我们的主要贡献如下：

- 我们提出了一种新方法，图聚合和推理网络（GAIN），它具有双图设计，以更好地应对文档级 RE 任务。

- 我们引入了一个异构的提及级图 (hMG) 和基于图的神经网络，以模拟文档中不同提及之间的交互并提供文档感知提及表示。

- 我们引入了实体级图 (EG) 并提出了一种新的路径推理机制，用于实体之间的关系推理。

我们在公共 DocRED 数据集上评估 GAIN。 它以 2.85 F1 分数显着优于之前最先进的模型。 进一步的分析证明了 GAIN 能够聚合文档感知上下文信息并推断文档的逻辑关系。

## 2 任务制定

我们将文档级关系提取任务制定如下。给定一个由 N 个句子组成的文档 D = {si}N i=1 和各种实体 E = {ei}P i=1，其中 si = {wj}M j=1 指的是第 i 个句子组成的 M 个词，ei = {mj}Q j=1 并且 mj 指的是属于第 i 个实体的第 j 个提及的词的跨度，任务旨在提取 E 中不同实体之间的关系，即 {(  ei, rij, ej)|ei, ej ∈ E, rij ∈ R}，其中 R 是预定义的关系类型集。

在我们的论文中，实体 ei 和 ej 之间的关系 rij 被定义为句间关系，当且仅当 Sei ∩ Sej = ∅，其中 Sei 表示那些包含 ei 的句子。 相反，关系 rij 被定义为句内，当且仅当 Sei∩Sej ̸= ∅。 我们还将 K-hop 关系推理定义为基于现有关系的 K 长度链预测关系 rij，其中 ei 和 ej 是推理链的头和尾，即 ei r1 −→ em r2 −→ 。  .  .  en rK −→ ej ⇒ ei rij −→ ej。

## 3 图聚合和推理网络 (GAIN)

GAIN主要由4个模块组成：编码模块（3.1节）、提及级图聚合模块（3.2节）、实体级图推理模块（3.3节）、分类模块（3.4节），如图 在图 2 中。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/b35d161a9a6df59dc34edc8b878522fbea77f5f2/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/Double%20Graph/figure/figure_2.png)

图 2：GAIN 的整体架构。 首先，上下文编码器使用输入文档来获取每个单词的上下文化表示。 然后，使用提及节点和文档节点构建提及级图。 应用 GCN 后，图被转换为实体级图，其中实体之间的路径被识别以进行推理。 最后，分类模块根据上述信息预测目标关系。 不同的实体有不同的颜色。 提及节点中的数字 i 表示它属于第 i 个句子。

#### 3.1 编码模型

在编码模块中，我们将包含 n 个单词的文档 D = {wi}n i=1 转换为向量序列 {gi}n i=1。 继姚等人。  (2019)，对于 D 中的每个词 wi，我们首先将其词嵌入与实体类型嵌入和共指嵌入连接起来：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/b35d161a9a6df59dc34edc8b878522fbea77f5f2/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/Double%20Graph/figure/formula_1.png)

其中Ew(·)、Et(·)和Ec(·)分别表示词嵌入层、实体类型嵌入层和共指嵌入层。  ti 和 ci 被命名为实体类型和实体 id。 我们为那些不属于任何实体的词引入 None 实体类型和 id。

然后将向量化的词表示输入编码器以获得每个词的上下文敏感表示：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/b35d161a9a6df59dc34edc8b878522fbea77f5f2/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/Double%20Graph/figure/formula_2.png)

其中编码器可以是 LSTM 或其他模型。

#### 3.2 提及级图聚合模块

为了对提及和实体之间的文档级信息和交互进行建模，构建了一个异构的提及级图 (hMG)。

hMG 有两种不同的节点：提及节点和文档节点。 每个提及节点表示一个实体的一个特定提及。 并且 hMG 还有一个文档节点，旨在对整体文档信息进行建模。 我们认为该节点可以作为与不同提及项交互的枢轴，从而减少文档中它们之间的长距离。

hMG 中存在三种类型的边：

- 实体内边缘：提及同一实体的提及与实体内边缘完全连接。通过这种方式，可以对同一实体的不同提及项之间的交互进行建模。
- 实体间边缘：如果它们同时出现在单个句子中，则对不同实体的两次提及与实体间边缘相关联。 通过这种方式，实体之间的交互可以通过它们的提及的同时出现来建模。
- 文档边缘：所有提及都通过文档边缘连接到文档节点。通过这种连接，文档节点可以处理所有提及并启用文档和提及之间的交互。此外，两个提及节点之间的距离最多为两个，以文档节点为枢轴。 因此可以更好地建模长距离依赖。

接下来，我们在 hMG 上应用图卷积网络（Kipf 和 Welling，2017 年）来聚合来自邻居的特征。 给定第 l 层的节点 u，图卷积操作可以定义为：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/b35d161a9a6df59dc34edc8b878522fbea77f5f2/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/Double%20Graph/figure/formula_3.png)

其中 K 是不同类型的边，W (l) k ∈ Rd×d 和 b(l) k ∈ Rd 是可训练的参数。  Nk(u) 表示在第 k 条边上连接的节点 u 的邻居。  σ 是一个激活函数（例如，ReLU）.

GCN的不同层表达不同抽象层次的特征，因此为了覆盖所有层次的特征，我们将每一层的隐藏状态串联起来，形成节点u的最终表示：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/b35d161a9a6df59dc34edc8b878522fbea77f5f2/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/Double%20Graph/figure/formula_4.png)

其中 h(0) u 是节点 u 的初始表示。对于文档中从第 s 个单词到第 t 个单词的提及，h(0) u = 1 t−s+1 �tj=s gj 并且对于文档节点，它使用文档表示输出进行初始化 来自编码模块。

#### 3.3 实体级图推理模块

在本小节中，我们将介绍实体级图 (EG) 和路径推理机制。 首先，将引用相同实体的提及合并到实体节点，以获得EG中的节点。 请注意，我们不考虑 EG 中的文档节点。 对于第 i 个实体节点 ei 被提及 N 次，它由其 N 次提及表示的平均值表示：

成节点u的最终表示：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/b35d161a9a6df59dc34edc8b878522fbea77f5f2/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/Double%20Graph/figure/formula_5.png)

然后，我们合并所有连接相同两个实体的提及项的实体间边，以获得 EG 中的边。  EG中从ei到ej的有向边的表示定义为：

成节点u的最终表示：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/b35d161a9a6df59dc34edc8b878522fbea77f5f2/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/Double%20Graph/figure/formula_6.png)

其中 Wq 和 bq 是可训练参数，σ 是激活函数（例如 ReLU）。

基于向量化的边表示，头实体eh和尾实体et之间经过实体eo的第i条路径表示为：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/b35d161a9a6df59dc34edc8b878522fbea77f5f2/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/Double%20Graph/figure/formula_7.png)

请注意，我们这里只考虑两跳路径，而它可以很容易地扩展到多跳路径。

我们还引入了注意力机制 (Bahdanau et al., 2015)，使用实体对 (eh, et) 作为查询，融合 eh 和 et 之间不同路径的信息。

基于向量化的边表示，头实体eh和尾实体et之间经过实体eo的第i条路径表示为：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/b35d161a9a6df59dc34edc8b878522fbea77f5f2/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/Double%20Graph/figure/formula_8.png)

其中 αi 是第 i 条路径的归一化注意力权重。 因此，该模型将更加关注有用的路径。  σ 是一个激活函数。

有了这个模块，一个实体可以通过从它的提及中融合信息来表示，这些信息通常分布在多个句子中。 此外，潜在的推理线索由实体之间的不同路径建模。 然后它们可以与注意力机制集成，以便我们将潜在的逻辑推理链考虑在内来预测关系。

#### 3.4 分类模块

对于每个实体对（eh，et），我们连接以下表示：（1）在实体级图中派生的头尾实体表示eh和et，通过比较操作（Mou et al., 2016）来加强 特征，即两个实体的表示之间减法的绝对值，|eh − et|，和元素相乘，eh ⊙ et；  (2) 文档节点在 Mention-level Graph 中的表示，mdoc，因为它可以帮助聚合跨句信息并提供文档感知表示；  (3)综合推理路径信息ph,t。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/b35d161a9a6df59dc34edc8b878522fbea77f5f2/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/Double%20Graph/figure/formula_9.png)

最后，我们将任务制定为多标签分类任务并预测实体之间的关系：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/b35d161a9a6df59dc34edc8b878522fbea77f5f2/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/Double%20Graph/figure/formula_10.png)

其中 Wa、Wb、ba、bb 是可训练参数，σ 是激活函数（例如 ReLU）。 我们使用二元交叉熵作为分类损失以端到端的方式训练我们的模型：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/b35d161a9a6df59dc34edc8b878522fbea77f5f2/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/4.%E6%96%87%E6%A1%A3%E6%8A%BD%E5%8F%96/Double%20Graph/figure/formula_11.png)

其中S表示整个语料库，I(·)表示指示函数。

## 4 实验



## 5 相关工作



## 6 总结



