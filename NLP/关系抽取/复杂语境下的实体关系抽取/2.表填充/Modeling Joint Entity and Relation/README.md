# 用表表示法建模联合实体和关系提取

# (Modeling Joint Entity and Relation Extraction with Table Representation)

## 摘要

本文提出了一种基于历史的结构化学习方法，可以联合提取句子中的实体和关系。我们介绍了一种新颖的简单灵活的实体和关系表表示。 我们研究了几个特征设置、搜索顺序和学习方法，并在表上进行了不精确搜索。 实验结果表明，联合学习方法通过结合全局特征并选择合适的学习方法和搜索顺序，显着优于管道方法。

## 前言

从文本中提取实体和关系传统上被视为两个独立子任务的管道：实体识别和关系提取。 这种分离使任务易于处理，但它忽略了子任务之间和内部的潜在依赖关系。 首先，由于实体识别不受关系抽取的影响，实体识别中的错误会传播到关系抽取。   其次，关系抽取通常被视为实体对上的多类分类问题，因此忽略实体对之间的依赖关系。 这些依赖关系的示例如图 1 所示。对于子任务之间的依赖关系，Live in 关系需要 PER 和 LOC 实体，反之亦然。 对于子任务内的依赖关系，“Mrs.   茑山”和“日本”可以从另外两种关系中推断出来。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/figure_1.png)

图 1：实体和关系示例（Roth 和 Yih，2004 年）。 人员 (PER) 和位置 (LOC) 实体通过居住和位于关系连接。

图 1 还显示该任务具有灵活的图结构。 这种结构通常不会覆盖句子中的所有单词，这与词性 (POS) 标记和依存分析等其他自然语言处理 (NLP) 任务不同，因此局部约束被认为在任务中更为重要。

联合学习方法（Yang 和 Cardie，2013 年；Singh 等人，2013 年）将这些依赖关系和局部约束纳入其模型； 然而，大多数方法都很耗时，并且采用由多个模型组成的复杂结构。  Li 和 Ji (2014) 最近提出了一种基于历史的结构化学习方法，它比其他方法更简单、计算效率更高。 虽然这种方法很有前途，但它仍然具有搜索的复杂性，并且部分由于其半马尔可夫表示限制了搜索顺序，因此没有充分研究基于历史的学习的潜力。

在本文中，我们引入了一个**实体和关系表**来解决表示任务的困难。 我们建议使用基于历史的结构化学习来联合提取实体和关系。 这种表格表示将任务简化为一个表格填充问题，并使任务足够灵活，可以合并以前基于历史的方法中没有解决的几个增强功能，例如解码中的搜索顺序、从关系到实体的全局特征、 以及几种不精确搜索的学习方法。

## 2 方法

在本节中，我们首先介绍一个实体和关系表，用于表示句子中的整个实体和关系结构。 然后我们在表上概述我们的模型。 我们最后解释了我们模型中的解码、学习、搜索顺序和特征。

#### 2.1 实体和关系表

我们在这项工作中处理的任务是从句子中提取实体及其关系。 实体是键入的并且可能跨越多个单词。 关系是类型化和定向的。

我们用词来表示实体和关系。我们假设实体不重叠。 我们采用了一种 BILOU（开始、内部、最后、外部、单位）编码方案，该方案已被证明优于传统的 BIO 方案（Ratinov 和 Roth，2009 年），并且我们将证明该方案在词之间和词之间引入了几种标签依赖性。  §2.3.2 中的词和关系。 根据与对应实体的相对位置和实体的类型为单词分配标签。 关系用它们的类型和方向来表示。  ⊥ 表示非关系对，→ 和 ← 分别表示从左到右和从右到左的关系。 关系不是在实体上定义的，而是在单词上定义的，因为在提取关系时并不总是给出实体。 实体上的关系映射到实体的最后一个词上的关系。

基于这种表示，我们提出了一个实体和关系表，它联合表示一个句子中的实体和关系。 图2说明了图1中一个例子对应的实体和关系表。我们只使用下三角部分，因为表是对称的，所以当一个词中有n个词时，单元格的数量是n(n+1)/2 句子。 使用这种实体和关系表表示，联合提取问题可以映射到表填充问题，因为将标签分配给表中的单元格。

#### 2.2 模型

我们通过一种基于历史的结构化学习方法来解决表格填充问题，该方法将标签一一分配给单元格。 除了表格表示外，这与传统的基于历史的模型（Collins，2002）大致相同。

设 x 是一个输入表，Y(x) 是该表的所有可能分配，s(x, y) 是评估 y ∈ Y(x) 到 x 的分配的评分函数。 有了这些定义，我们定义了我们的模型来预测最可能的分配，如下所示：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/formula_1.png)

这个评分函数是一个可分解的函数，每个分解的函数都会评估一个标签对表中一个单元格的分配。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/formula_2.png)

这里，i 代表表格中单元格的索引，这将在 §2.3.1 中解释。 分解后的函数 s(x, y, 1, i) 对应于第 i 个单元格。 分解后的函数表示为线性模型，即特征及其相应权重的内积。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/formula_3.png)

评分函数进一步分为以下两个函数：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/formula_4.png)

这里，slocal(x, y, i) 是一个局部评分函数，它在不考虑其他分配的情况下评估对第 i 个单元格的分配，而 sglobal(x, y, 1, i) 是一个评估分配的全局评分函数 在第 1 到 (i − 1) 次分配的上下文中。 该全局评分函数表示实体之间、关系之间以及实体与关系之间的依赖关系。 类似地，特征 f 被分为局部特征 flocal 和全局特征 fglobal，它们被定义在其目标单元和周围的上下文中。 这些特性将在 §2.5 中解释。 权重 w 也可以划分，但它们在学习中共同调整，如 2.4 节所示。

#### 2.3 解码

等式（2）中的评分函数 s(x, y, 1, i) 使用了前面所有的赋值，并且不依赖于马尔可夫假设，因此我们不能使用动态规划。

我们改为使用波束搜索来找到得分最高的最佳分配（Collins 和 Roark，2004）。 当从一个单元格移动到下一个单元格时，波束搜索将标签一个一个地分配给单元格，并保留前 K 个最佳分配，并在将标签分配给所有单元格时返回最佳分配。 使用波束搜索进行解码的伪代码如图 3 所示。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/figure_2.png)

图 2：图 1 中示例的实体和关系表。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/figure_3.png)

图 3：使用波束搜索解码。  A(i, t) 返回表 t 第 i 个单元格的可能赋值，而 append(a, t) 返回用赋值 a 更新的表 t。

我们将在以下小节中解释如何将表映射到序列（图 3 中的第 2 行），以及如何计算可能的分配（图 3 中的第 6 行）。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/figure_4.png)

图 4：静态搜索表单

##### 2.3.1 表到序列映射

输入表中的单元格最初以二维索引。 要将§2.2 中的模型应用于单元格，我们需要将二维表映射到一维序列。 这相当于在表中定义搜索顺序，因此我们将交替使用术语“映射”和“搜索顺序”。

由于尝试所有可能的映射是不可行的，我们定义了六个有希望的静态映射（搜索顺序），如图 4 所示。请注意，标题中的“左”和“右”方向对应的不是词序，而是表格。 我们定义了两个映射（图 4(a) 和 4(b)），它们在“从上到下”的顺序上具有最高优先级，它向前检查一个句子（从一个句子的开头）。 同样，我们还定义了两个映射（图 4(c) 和 4(d)）在“从右到左”的顺序上具有最高优先级，它们向后检查一个句子（从句子的末尾）。 从另一个角度来看，实体在图 4(b) 和 4(c) 中的关系之前被检测到，而句子中的顺序在图 4(a) 和 4(d) 中被优先考虑。 我们进一步定义了两个紧密优先映射（图 4(e) 和 4(f)），因为实体比关系更容易找到，而密切关系比远距离关系更容易找到。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/table_2.png)

表 2：从实体到关系的标签依赖关系。

我们还研究了使用简单优先策略的动态映射（搜索顺序）（Goldberg 和 Elhadad，2010 年）。动态映射与上面的静态映射不同，因为我们在每次解码之前对单元重新排序1。 我们使用局部评分函数评估单元格，并为单元格分配索引，以便分数较高的单元格具有更高的优先级。 除了这个简单的简单优先策略之外，我们还定义了另外两个动态映射，通过将简单优先策略与以下两个策略之一相结合来限制重新排序：实体优先（在关系之前检测到所有实体）和关闭 -first（在较远的单元之前检测到较近的单元）策略。

##### 2.3.2 标签依赖

为了避免对表的非法赋值，我们必须根据前面的赋值限制对单元格的可能赋值。 这种限制还可以降低计算成本。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/table_3.png)

表 3：实体之间的标签依赖关系。TYPE 表示实体类型，O/S 表示单词在句子之外。

我们考虑单元格之间的所有依赖关系，以允许以任意顺序为单元格分配标签。 我们在 §2.1 中对实体和关系的表示引入了实体之间以及实体和关系之间的依赖关系。表 1-3 总结了这些对句子中第 i 个单词 wi 的依赖关系。 如果某些实体类型涉及有限数量的关系类型，我们可以进一步利用实体类型和关系类型之间的依赖关系，反之亦然。 我们注意到实体类型和关系类型之间的依赖关系不仅包括参与关系的词，还包括它们周围的词。 例如，wi-1 上的标签可以限制涉及 wi 的关系类型。 我们在评估中使用了这些类型依赖，但我们在这里省略了这些依赖，因为这些依赖依赖于任务。

#### 2.4 学习过程

学习的目标是通过调整公式 3 中评分函数中的权重 w 来最小化预测分配 y∗ 和黄金分配 ygold 之间的错误。我们采用基于边际的结构化学习方法来调整权重 w。 伪代码如图 5 所示。这种方法通过以下方式增强了传统的结构化感知器 (Collins, 2002)。 首先，我们在评分函数中加入了一个边际 ∆，如下所示，这样错误的分配与黄金分配的差异很小（图 5 中的第 4 行和第 6 行）（Freund 和 Schapire，1999）。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/figure_5.png)

图 5：具有最大违规更新的基于保证金的结构化学习方法。update(w, f(x, ygold, 1, m), f(x, y∗, 1, m)) 取决于采用的学习方法。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/formula_5.png)

与评分函数 s 类似，边际 ∆ 被定义为使用 0-1 损失的可分解函数，如下所示：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/formula_6.png)

其次，我们根据 Huang 等人的最大违反更新规则更新权重 w。(2012)（图 5 中的第 6-7 行）。 最后，我们不仅使用感知器（Collins，2002），还使用 AROW（Mejer 和 Crammer，2010；Crammer 等，2013）、AdaGrad（Duchi 等，2011）和 DCD-SSVM（Chang 和 Yih，2013）  ) 用于学习方法（图 5 中的第 7 行。）我们采用除 DCD-SSVM 之外的参数平均。  AROW 和 AdaGrad 分别存储协方差和特征计数的附加信息，而 DCDSSVM 保留一个工作集并在每次迭代中执行附加更新。 限于篇幅，具体的学习方法请参考论文。

#### 2.5 特征

在这里，我们解释了§2.2 中介绍的局部特征 flocal 和全局特征 fglobal。

##### 2.5.1 局部特征

我们的重点不是为实体和关系开发有用的局部特征，因此我们结合了现有工作中的几个特征来实现合理的基线。 表 4 总结了局部特征。实体（或词）的局部特征类似于 Florian 等人使用的特征。  (2003)，但对某些特征进行了概括和扩展，排除了地名词典特征。 对于关系（或词对），我们使用并扩展了 Miwa 等人的特征。  (2009)。

##### 2.5.2 全局特征

我们设计全局特征来表示实体和关系之间的依赖关系。 表 5 总结了全局特征 2。 当所有信息在解码期间可用时，这些全局特征被激活。

我们整合了标签依赖特性，如实体的传统顺序标签。尽管我们的模型可以包含实体之间的其他非局部特征（Ratinov 和 Roth，2009），但我们不包括它们，因为实体和关系的全局特征可以覆盖它们。 我们为关系设计了三种类型的全局特征。当所有参与关系都不是⊥（非关系）时，这些特征被激活。 除“Crossing”类别外的特征类似于 Li and Ji (2014) 中的全局关系特征。我们进一步整合了实体和关系的全局特征。 当关系标签不是 ⊥ 时，这些特征被激活。 这些特征可以充当实体和关系之间的桥梁。

## 3 评估

在本节中，我们首先介绍我们用于评估的语料库和评估指标。 然后我们在训练数据集上展示性能，解释用于测试集评估的参数，并在测试数据集上展示性能。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/table_4.png)

表 4：局部特征。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/table_5.png)

表 5：全局特征。

#### 3.1 评估设置

 我们使用了 Roth 和 Yih (2004)3 的实体和关系识别语料库。 语料库定义了四种命名实体类型 Location、Organization、Person 和 Other 以及五种关系类型 Kill、Live In、Located In、OrgBased In 和 Work For。

所有实体都是原始语料库中的单词，因为实体中的所有空格都被替换为斜杠。以前的系统（Roth 和 Yih，2007 年；Kate 和 Mooney，2010 年）按原样使用这些词边界，将边界视为给定的，并仅关注实体分类问题。 与此类系统不同，我们通过用空格替换这些斜杠来恢复这些空格，以评估该语料库上的实体边界检测性能。 由于这种替换和边界检测问题的包含，我们的任务比原始任务更具挑战性，我们的结果与以前的系统无法比较。

语料库包含 1,441 个句子，其中至少包含一个关系。 我们将数据集拆分为训练（1,153 个句子）和盲测（288 个句子）数据集，而不是之前系统对整个语料库进行 5 倍交叉验证，并在训练数据集上开发系统。 我们在训练数据集上使用 5 折交叉验证调整超参数，并评估测试集的性能。

我们准备了一个管道方法作为基线。我们首先使用局部和全局特征训练实体识别模型，然后使用局部特征和全局特征训练关系提取模型，表 5 中没有全局“关系”特征。我们在这个过程中没有使用全局“关系”特征 基线，因为通常将关系提取视为多类分类问题。、

我们使用两个句法解析器 Enju（Miyao 和 Tsujii，2008）和 LRDEP（Sagae 和 Tsujii，2007）的结果提取特征。 我们采用了特征散列（Weinberger et al., 2009）并将特征空间限制为 224。特征的数量因类别和目标而异。 在我们的初步实验中，它们还导致了偏向于实体而非关系的预测。 因此，我们选择按如下方式重新调整特征。 我们将每个特征类别的局部特征归一化，然后对每个目标进行归一化。 我们还为每个特征类别标准化了全局特征，但我们没有为每个目标标准化它们，因为在解码期间标准化是不可能的。 我们改为缩放全局特征，并通过使用上述相同的 5 倍交叉验证来调整缩放因子。

我们使用实体关系的 F1 分数作为我们的主要评估指标，并将其用于调整参数。 在该措施中，当实体的偏移量和类型以及关系的类型都正确时，认为具有两个实体的关系是正确的。 我们还通过检查它们相应的单元格，在测试数据集上单独评估实体和关系的 F1 分数。 当偏移量和类型正确时一个实体是正确的，当类型正确并且两个实体的最后一个字正确时一个关系是正确的。

#### 3.2 训练集数据上的表现

调查所有参数的组合是不可行的，因此我们通过使用训练数据集的评估结果贪婪地搜索默认参数设置。 默认参数设置是除光束尺寸外的最佳设置。 当我们将每个参数与默认参数设置不同时，我们显示了图 6 中训练数据集的学习曲线。 我们采用了 5 折交叉验证。 默认参数设置使用DCD-SSVM作为学习方法，entity-first，easy-first作为搜索顺序，局部和全局特征，8作为beam size。本节讨论这些参数如何影响训练数据集的性能，并解释如何为测试集选择参数设置。

图 6(a) 比较了 §2.4 中介绍的学习方法。  DCD-SSVM 和 AdaGrad 的表现略好于感知器，后者经常用于基于历史的结构化学习。  AROW 没有表现出与其他人可比的表现。 我们运行了 100 次迭代来找到使学习曲线饱和的迭代次数。 大量迭代需要时间，并且 DCD-SSVM 的性能在 30 次迭代后几乎收敛，因此我们使用 50 次迭代对训练数据集进行其他评估。  AdaGrad 获得最高性能的速度比其他学习方法更快，而 AROW 的收敛速度比其他方法慢，因此我们在测试数据集上为 AdaGrad 使用了 10 次，为 AROW 使用了 90 次，并为其他设置使用了 50 次迭代。

如图 6(b) 所示，通过加宽光束来提高性能，但随着光束尺寸的增加，性能的提高逐渐减弱。 由于更宽的光束需要更多的训练和测试时间，我们选择了 8 作为光束尺寸。

图 6(c) 显示了联合学习的效果以及 §2.5 中解释的特征。 我们展示了 §3.1 中引入的流水线方法（Pipeline）的性能，以及单独使用局部特征（Local）、没有全局“关系”特征的局部和全局特征的性能（局部+全局（-relation））和 所有本地和全局功能（本地+全局）。我们注意到流水线显示了流水线方法中关系提取的学习曲线。  “Local+global (-relation)”中的特征与pipeline方法中的特征相同，结果表明联合学习方法的表现略好于pipeline方法。与现有管道方法一样，全局“实体”和“实体+关系”特征的结合提高了性能，与关系相关的特征进一步提高了性能。

§2.3.1 中的静态搜索顺序也影响了性能，如图 6(d) 所示，尽管在联合实体和关系提取中没有研究搜索顺序。 令人惊讶的是，在 F1 分数中，具有最佳顺序和最差顺序的性能之间的差距约为 0.04，具有统计学意义，并且性能可能比图 6(c) 中的流水线方法差。这意味着如果我们不仔细考虑搜索顺序，联合学习的改进很容易被抵消。 同样令人惊讶的是，第二差的顺序（图 4（b））是最直观的“从左到右”的顺序，在六个搜索顺序中与 Li and Ji (2014) 中的顺序最接近。

图 6(e) 显示了动态搜索顺序的性能。 不幸的是，easy-first 策略在这个实体和关系任务上效果不佳，但是，通过这两个增强，动态订单的表现与图 6(d) 中的最佳静态订单一样。 这表明实体应该早于该数据集上的关系被检测到。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/figure_6.png)

图 6：使用 5 折交叉验证在训练数据集上提取实体和关系的学习曲线。

#### 3.3 测试集上的表现

图 6(e) 显示了动态搜索顺序的性能。 不幸的是，easy-first 策略在这个实体和关系任务上效果不佳，但是，通过这两个增强，动态订单的表现与图 6(d) 中的最佳静态订单一样。 这表明实体应该早于该数据集上的关系被检测到。

与训练数据集的结果不同，AdaGrad 和 AROW 的性能明显低于感知器和 DCD-SSVM，并且它们的性能略低于流水线方法。 该结果表明 DCD-SSVM 在不精确搜索方面表现良好，学习方法的选择会显着影响实体和关系提取性能。

联合学习方法显示出对具有关系相关全局特征的管道方法的显着改进，尽管单独的联合学习方法并没有显示出对管道方法的显着改进。不幸的是，没有联合学习方法在实体识别方面优于管道方法。这可能部分是因为超参数被调整到主要措施。 管道方法的结果还表明，更好的实体识别性能并不一定会提高关系提取性能。

搜索顺序也影响了性能，最差的顺序（从右到左，从下到上）和最好的顺序（先关闭，从左到右）有显着差异。 最差顺序的性能比流水线方法差，尽管差异并不显着。 这些结果表明，有必要仔细选择联合实体和关系提取任务的搜索顺序。

#### 3.4 与其他系统的比较

为了将我们的模型与其他系统进行比较（Roth 和 Yih，2007 年；Kate 和 Mooney，2010 年），我们在给定实体边界时评估了我们模型的性能。 与我们在 §3.1 中的设置不同，我们使用了 BILOU 方案中编码的黄金实体边界，并为边界分配了实体标签。 我们在 Roth 和 Yih (2007) 之后对数据集进行了 5 折交叉验证，尽管拆分与他们的不同，因为他们的拆分不可用。 我们使用 §3.2 中的默认参数设置进行比较。

评价结果如表7所示。 虽然我们无法直接比较结果，但我们的模型比其他模型表现更好。 与表 6 相比，表 7 还表明，包含实体边界检测会使 F-score 的性能降低约 0.09。

## 4 相关工作

已经在几个 NLP 任务中研究了结构化学习中的搜索顺序。 在顺序标记任务中经常研究从左到右和从右到左的排序（Kudo 和 Matsumoto，2001）。Easy-first 策略首先由 Goldberg 和 Elhadad (2010) 引入用于依存解析，并成功地应用于多项任务，例如联合词性标注和依存解析 (Ma et al., 2012) 和共同引用解析 (Stoyanov) 和艾斯纳，2012 年）。 然而，搜索顺序并未集中在关系提取任务中。

命名实体识别（Florian et al., 2003; Nadeau and Sekine, 2007）和关系抽取（Zelenko et al., 2003; Miwa et al., 2009）通常被视为单独的任务，但之前有一些研究表明 在学习中共同对待实体和关系。 大多数研究基于子任务的单个模型建立联合学习模型，例如整数线性规划 (ILP)（Roth 和 Yih，2007 年；Yang 和 Cardie，2013 年）和 Card-Pyramid Parsing（Kate 和 Mooney，2010 年）。 我们的方法不需要这样的单个模型，它还可以检测除 Yang 和 Cardie (2013) 之外的这些方法没有处理的实体边界。 其他研究（Yu 和 Lam，2010 年；Singh 等人，2013 年）建立了全局概率图形模型。 他们需要计算变量的分布，但我们的方法不需要。  Li and Ji (2014) 提出了一种联合寻找实体和关系的方法。他们在表示实体中加入了半马尔可夫链，并在搜索过程中定义了两个动作，但我们的方法没有使用这样的表示和动作，因此调查搜索顺序更加简单和灵活。

## 5 总结

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/table_6.png)

表 6：实体和关系提取在测试数据集上的性能（精度/召回率/F1 分数）。† 表示§3.2 中的默认参数设置，而 ⋆ 表示比下划线的“Pipeline”基线显着改进（p<0.05）。 标签 (a)-(f) 对应于图 4 中的标签。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Modeling%20Joint%20Entity%20and%20Relation/figure/table_7.png)

表 7：使用 5 折交叉验证（精度/召回率/F1 分数）对数据集进行实体分类和关系提取的结果。

在本文中，我们提出了一种基于历史的结构化学习方法，可以联合检测实体和关系。 我们引入了一个新的实体 和联合表示实体的关系表 和关系，并展示了实体和重新 翻译提取任务可以映射到一个简单的 填表问题。 我们还调查了搜索 已修复的命令和学习方法 在以往的研究中。 实验结果表明 联合学习方法优于 管道方法和适当的选择 学习方法和搜索顺序对于 在此任务上产生高性能。 

作为未来的工作，我们计划将此方法应用于其他关系提取任务，并为关系提取任务探索更合适的搜索顺序。我们还计划研究该表表示在其他任务中的潜力，例如语义解析和共引用解析。









