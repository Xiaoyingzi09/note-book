# Joint entity recognition and relation extraction as a multi-head selection problem

# 作为多头选择问题的联合实体识别和关系提取

## 摘要

用于联合实体识别和关系提取的最先进模型强烈依赖于外部自然语言处理 (NLP) 工具，例如 POS（词性）标注器和依赖解析器。 因此，这种联合模型的性能取决于从这些 NLP 工具获得的特征的质量。 但是，对于各种语言和上下文，这些功能并不总是准确的。 在本文中，我们提出了一种联合神经模型，它同时执行实体识别和关系提取，无需任何手动提取的特征或使用任何外部工具。 具体来说，我们使用 CRF（条件随机场）层对实体识别任务进行建模，并将关系提取任务建模为多头选择问题（即，可能为每个实体识别多个关系）。 我们提出了一个广泛的实验设置，以使用来自各种上下文（即新闻、生物医学、房地产）和语言（即英语、荷兰语）的数据集来证明我们的方法的有效性。 我们的模型优于之前使用自动提取特征的神经模型，同时它在基于特征的神经模型的合理范围内执行，甚至击败它们。

关键词：实体识别、关系抽取、多头选择、联合模型、序列标注

## 1 前言

实体识别和关系抽取的目标是从非结构化文本中发现实体提及的关系结构。 它是信息提取中的一个核心问题，因为它对于知识库填充和问答等任务至关重要。

该问题传统上作为两个独立的子任务来处理，即 (i) 命名实体识别 (NER) (Nadeau & Sekine, 2007) 和 (ii) 关系提取 (RE) (Bach & Badaskar, 2007)，在管道设置中。 管道模型的主要限制是：（i）组件（即 NER 和 RE）之间的错误传播和（ii）来自一项任务的可能有用信息未被另一项利用（例如，识别关系可能的 Works 有助于 NER 模块检测两个实体的类型，即 PER、ORG，反之亦然）。 另一方面，最近的研究建议使用联合模型来检测实体及其关系，以克服上述问题并实现最先进的性能（Li & Ji，2014；Miwa & Sasaki，2014）。

以前的联合模型严重依赖手工制作的功能。 神经网络的最新进展缓解了手动特征工程的问题，但其中一些仍然依赖于 NLP 工具（例如，词性标注器、依赖解析器）。  Miwa & Bansal (2016) 提出了一种基于循环神经网络 (RNN) 的联合模型，该模型使用双向顺序 LSTM（长短期记忆）对实体进行建模，并使用树-LSTM 将依赖树信息考虑在内来对关系进行建模 实体之间。 依赖信息是使用外部依赖解析器提取的。 同样，在 Li 等人的工作中。  (2017) 为了从生物医学文本中提取实体和关系，应用了一个也使用树-LSTM 的模型来提取依赖信息。 古普塔等人。  (2016) 提出了一种依赖 RNN 的方法，但使用了大量手工制作的特征和额外的 NLP 工具来提取特征，如 POS 标签等。 Adel & Schüutze (2017) 使用卷积复制实体周围的上下文 神经网络（CNN）。 请注意，上述工作检查实体对以进行关系提取，而不是直接对整个句子建模。 这意味着不会考虑同一句子中其他实体对的关系——这可能有助于决定特定对的关系类型。  Katiyar & Cardie (2017) 提出了一种基于 LSTM 的神经联合模型，他们一次对整个句子进行建模，但仍然没有处理多重关系的原则性方法。 贝库利斯等人。  (2018) 引入了二次评分层来同时对两个任务进行建模。 这种方法的局限性在于只能将单个关系分配给令牌，而与具有线性复杂度的标准方法相比，实体识别任务的时间复杂度有所增加。

在这项工作中，我们专注于一个新的通用联合模型，它同时执行实体识别和关系提取这两个任务，并且可以一起处理多个关系。 我们的模型在许多不同的上下文（即新闻、生物医学、房地产）和语言（即英语、荷兰语）中实现了最先进的性能，而无需依赖任何手动设计的功能或额外的 NLP 工具。 总之，我们提出的模型（将在第 3 节中详细介绍）解决了我们在相关工作（第 2 节）中确定的联合实体识别和关系提取的几个缺点：（i）我们的模型不依赖于外部 NLP 工具，也不依赖于 手工制作的特征，（ii）同时提取同一文本片段（通常是一个句子）中的实体和关系，其中（iii）一个实体可以同时涉及多个关系。

具体来说，Miwa & Bansal (2016) 的模型依赖于依赖解析器，它在特定语言（即英语）和上下文（即新闻）上表现特别好。 然而，我们的目标是开发一个在各种设置中都能很好地泛化的模型，因此只使用在训练期间学习的自动提取的特征。例如，Miwa & Bansal (2016) 和 Li 等人。  (2017) 在不同的上下文中使用完全相同的模型，即分别使用新闻 (ACE04) 和生物医学数据 (ADE)。 将我们的结果与 ADE 数据集进行比较，我们在 NER 任务上获得了 1.8% 的改进，在 RE 任务上获得了约 3% 的改进。 另一方面，我们的模型在 ACE04 数据集上的表现在合理的范围内（在 NER 任务中为 ~0.6%，在 RE 任务中为 ~1%），而没有使用预先计算的特征。 这表明 Miwa & Bansal (2016) 的模型强烈依赖于依赖解析器提取的特征，不能很好地泛化到依赖解析器特征较弱的不同上下文中。
   与 Adel & Schüutze (2017) 相比，我们通过一次对所有实体和句子的关系进行建模来训练我们的模型。 这种类型的推理有利于获取有关相邻实体和关系的信息，而不是每次只检查一对实体。 最后，我们解决了 Katiyar & Cardie (2017) 和 Bekoulis 等人提出的模型的潜在问题。  (2017)，他们基本上假设类（即关系）是互斥的：我们通过将关系提取组件表述为多标签预测问题来解决这个问题。 1

为了证明所提出方法的有效性，我们在联合执行实体识别和关系提取（参见第 4 节和第 5 节）方面进行了迄今为止最大的实验评估（据我们所知），使用来自各个领域的不同数据集（ 即新闻、生物医学、房地产）和语言（即英语、荷兰语）。 具体来说，我们将我们的方法应用于四个数据集，即 ACE04（新闻）、药物不良事件（ADE）、荷兰房地产分类（DREC）和 CoNLL'04（新闻）。 我们的方法优于所有不依赖任何附加特征或工具的最先进方法，而与利用手工工程特征或 NLP 工具的方法相比，其性能非常接近（甚至在生物医学数据集中更好）  .

## 2 相关工作

实体识别和关系提取的任务可以在管道设置（Fundel 等人，2007；Gurulingappa 等人，2012a；Bekoulis 等人，2017）或联合模型（Miwa 和 Sasaki）中一一应用 , 2014; Miwa & Bansal, 2016; Bekoulis 等人, 2018)。 在本节中，我们将介绍每个任务的相关工作（即命名实体识别和关系提取）以及联合实体和关系提取的先前工作。

#### 2.1 命名实体识别

在我们的工作中，NER 是我们解决的第一个任务，以解决端到端关系提取问题。 已经提出了许多基于手工特征的 NER 任务的不同方法，例如 CRF（Lafferty 等人，2001 年）、最大边际马尔可夫网络（Taskar 等人，2003 年）和支持向量机（  SVM）用于结构化输出（Tsochantaridis 等人，2004 年），仅举几例。 最近，基于 CNN 和 RNN 的模型等深度学习方法已与 CRF 损失函数（Collobert 等人，2011 年；Huang 等人，2015 年；Lample 等人，2016 年；Ma & Hovy，2016 年）相结合，用于 纳。 这些方法在不依赖手工制作的特征的情况下，在公开可用的 NER 数据集上实现了最先进的性能。

#### 2. 关系抽取

我们将关系提取视为联合模型的第二个任务。 关系提取的主要方法依赖于手工制作的特征（Zelenko 等人，2003 年；Kambhatla，2004 年）或神经网络（Socher 等人，2012 年；Zeng 等人，2014 年）。基于特征的方法侧重于获得有效的手工特征，例如定义核函数（Zelenko 等人，2003 年；Culotta & Sorensen，2004 年）和设计词汇、句法、语义特征等（Kambhatla，2004 年；Rink &  Harabagiu，2010 年）。 已经提出了神经网络模型来克服手动设计手工制作的特征从而提高性能的问题。  CNN-（Zeng 等，2014；Xu 等，2015a；dos Santos 等，2015）和基于 RNN（Socher 等，2013；Zhang & Wang，2015；Xu 等，2015b） 引入了模型来自动提取词汇和句子级别的特征，从而更深入地理解语言。 武等人。  (2016) 使用集成方案将 CNN 和 RNN 结合起来，以实现最先进的结果。

#### 2.3 联合实体和关系抽取

实体和关系提取包括以下任务：（i）识别实体（在 2.1 节中描述）和（ii）提取它们之间的关系（在 2.2 节中描述）。已经提出了基于特征的联合模型（Kate & Mooney，2010；Yang & Cardie，2013；Li & Ji，2014；Miwa & Sasaki，2014）同时解决实体识别和关系提取 (RE) 子任务。 这些方法依赖于 NLP 工具（例如，词性标注器）或手动设计的特征的可用性，因此 (i) 需要额外的数据预处理工作，(ii) 在 NLP 工具不可靠的不同应用程序和语言设置中表现不佳 , (iii) 增加计算复杂度。 在本文中，我们引入了一种联合神经网络模型来克服上述问题并自动执行端到端关系提取，而无需任何手动特征工程或使用额外的 NLP 组件。

神经网络方法已被考虑用于解决联合设置（端到端关系提取）中的问题，通常包括使用 RNN 和 CNN（Miwa 和 Bansal，2016 年；Zheng 等人，2017 年；Li 等人，2016 年）。  , 2017)。 具体而言，Miwa & Bansal (2016) 提出使用双向树结构 RNN 来捕获依赖树信息（其中使用最先进的依赖解析器提取解析树），这已被证明对关系提取有益（Xu et  al., 2015a,b)。 李等人。  （2017 年）将 Miwa 和 Bansal（2016 年）的工作应用于生物医学文本，报告了两个生物医学数据集的最新性能。 古普塔等人。(2016) 建议使用大量手工制作的特征以及 RNN。  Adel & Schüutze (2017) 解决了实体分类任务（与 NER 不同，因为在实体分类中实体的边界是已知的，并且只应该预测实体的类型）和使用近似值的关系提取问题 全局归一化目标（即 CRF）：他们复制句子的上下文（实体的左右部分），一次将一个实体对馈送到 CNN 以进行关系提取。 因此，它们不会同时推断同一句子中的其他潜在实体和关系。  Katiyar & Cardie (2017) 和 Bekoulis 等人。  (2018) 在不使用任何依赖解析树特征的情况下，研究了带有注意力的 RNN，用于提取实体提及之间的关系。 与 Katiyar & Cardie (2017) 不同，在这项工作中，我们通过使用 sigmoid 损失获得多重关系和 NER 组件的 CRF 损失，将问题框架化为多头选择问题。 通过这种方式，我们能够独立预测不相互排斥的类，而不是在标记之间分配相等的概率值。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Joint%20recognition%20and%20relation%20extraction/figure/figure_1.png)

图 1：联合实体和关系提取的多头选择模型。 我们模型的输入是句子中的词，然后将其表示为词向量（即嵌入）。  BiLSTM 层为每个单词提取更复杂的表示。 然后 CRF 和 sigmoid 层能够为这两个任务产生输出。 每个标记（例如，史密斯）的输出是：（i）实体识别标签（例如，I-PER）和（ii）一组元组，包括实体的头部标记以及它们之间的关系类型（例如 , {(Center, Works for), (Atlanta, Lives in)})。

我们克服了 Bekoulis 等人描述的额外复杂性问题。  (2018)，通过将损失函数划分为 NER 和关系提取组件。 此外，我们能够处理多个关系，而不仅仅是预测单个关系，如 Bekoulis 等人对结构化房地产广告的应用所描述的那样。  (2018)。

## 3 Joint model

在本节中，我们展示了图 1 所示的多头联合模型。该模型能够同时识别实体（即类型和边界）以及它们之间的所有可能关系。 我们将问题表述为扩展先前工作（Zhang 等人，2017 年；Bekoulis 等人，2018 年）的多头选择问题，如第 2.3 节所述。 通过多头，我们的意思是任何特定实体都可能涉及与其他实体的多重关系。 如图 1 所示，模型的基本层是：（i）嵌入层，（ii）双向顺序 LSTM（BiLSTM）层，（iii）CRF 层和（iv）sigmoid 评分层。 在图 1 中，展示了来自 CoNLL04 数据集的一个例句。 我们模型的输入是一系列标记（即句子的单词），然后将其表示为词向量（即词嵌入）。  BiLSTM 层能够通过 RNN 结构为包含上下文的每个单词提取更复杂的表示。 然后 CRF 和 sigmoid 层能够为这两个任务产生输出。 每个令牌（例如，Smith）的输出是双重的：（i）实体识别标签（例如，I-PER，表示令牌位于 PER 类型的命名实体内）和（ii）包含头部的一组元组 实体的标记以及它们之间的关系类型（例如，{(Center, Works for), (Atlanta, Lives in)}）。 由于我们假设基于令牌的编码，我们只考虑实体的最后一个令牌作为另一个令牌的头部，消除冗余关系。例如，实体“John Smith”和“Disease Control Center”之间存在关系的Works。 我们没有连接实体的所有代币，而是仅将“Smith”与“Center”连接起来。 此外，对于没有关系的情况，我们引入了“N”标签，我们将令牌本身预测为头部。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Joint%20recognition%20and%20relation%20extraction/figure/figure_2.png)

图 2：详细嵌入层。  “Man”这个词的字符由在训练期间学习的字符向量（即嵌入）表示。 字符嵌入被馈送到 BiLSTM 并连接两个最终状态（向前和向后）。 向量 wchars 是单词的字符级表示。 然后将该向量进一步连接到词级表示 wword2vec 以获得完整的词嵌入向量。

#### 3.1 嵌入层

给定一个句子 w = w1, ..., wn 作为一个标记序列，词嵌入层负责将每个标记映射到一个词向量（wword2vec）。 我们使用 Skip-Gram word2vec 模型 (Mikolov et al., 2013) 使用预先训练的词嵌入。

在这项工作中，我们还使用了字符嵌入，因为它们通常应用于神经 NER（Ma & Hovy，2016 年；Lample 等人，2016 年）。 这种类型的嵌入能够捕获形态特征，例如前缀和后缀。 例如，在药物不良事件 (ADE) 数据集中，后缀“毒性”可以指定药物不良事件实体，例如“神经毒性”或“肝毒性”，因此信息量很大。 另一个例子可能是荷兰房地产分类 (DREC) 数据集中的荷兰语后缀“kamer”（英语中的“room”），用于指定空间实体“badkamer”（英语中的“浴室”）和“slaapkamer”（ 英语中的“卧室”）。在训练期间学习字符级嵌入，类似于 Ma & Hovy (2016) 和 Lample 等人。  (2016)。 在兰普尔等人的工作中。  (2016)，就 NER F1 分数而言，字符嵌入使性能提高了 3%。 在我们的工作中，通过结合字符嵌入，我们在表 2 中报告了总体 F1 得分增加了约 2%。 有关更多详细信息，请参阅第 5.2 节。

图 2 说明了基于其字符生成词嵌入的神经架构。 每个单词的字符由字符向量（即嵌入）表示。 字符嵌入被馈送到 BiLSTM 并连接两个最终状态（向前和向后）。 向量 wchars 是单词的字符级表示。 然后将该向量进一步连接到词级表示 wword2vec 以获得完整的词嵌入向量。

#### 3.2 双向LSTM编码层

RNN 通常用于对序列数据进行建模，并已成功应用于各种 NLP 任务（Sutskever 等人，2014 年；Lample 等人，2016 年；Miwa 和 Bansal，2016 年）。 在这项工作中，我们使用多层 LSTM，这是一种特定类型的 RNN，能够很好地捕获长期依赖关系（Bengio 等人，1994 年；Pascanu 等人，2013 年）。 我们采用了一个 BiLSTM，它能够从左到右（过去到未来）和从右到左（未来到过去）对信息进行编码。 这样，我们可以通过在时间步 i 连接前向 (⃗hi) 和后向 (⃗ hi) 输出来组合每个单词的双向信息。 时间步 i 处的 BiLSTM 输出可以写为：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Joint%20recognition%20and%20relation%20extraction/figure/formula_1.png)

#### 3.3 命名实体识别

我们将实体识别任务制定为序列标记问题，类似于之前在联合学习模型（Miwa & Bansal，2016；Li 等人，2017 年；Katiyar & Cardie，2017 年）和命名实体识别（Lample 等人，  2016 年；Ma & Hovy，2016 年）使用 BIO（开始、内部、外部）编码方案。 每个实体由句子中的多个连续标记组成，我们应该为句子中的每个标记分配一个标签。 这样我们就能够识别实体参数（开始和结束位置）及其类型（例如，ORG）。 为此，我们将 B 类型（开始）分配给实体的第一个标记，将 I 类型（内部）分配给实体内的所有其他标记，如果标记不属于某个标记，则将 O 标记（外部）分配给实体。 实体。 图 1 显示了分配给句子标记的 BIO 编码标签的示例。 在 CRF 层，可以观察到我们分配 B-ORG 和 I-ORG 标签分别指示实体“疾病控制中心”的开始和内部标记。 在 BiLSTM 层之上，我们使用 softmax 或 CRF 层来计算每个标记的最可能的实体标签。 我们计算每个实体标签的每个 token wi 的分数：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Joint%20recognition%20and%20relation%20extraction/figure/formula_2.png)

其中上标 (e) 用于表示 NER 任务，f(·) 是元素激活函数（即 relu，tanh），V (e) ∈ Rp×l，U (e) ∈ Rl×2d  , b(e) ∈ Rl，d 是 LSTM 的隐藏大小，p 是 NER 标签（例如，B-ORG）的数量，l 是层的宽度。 我们计算给定标记 wi 的所有候选标签的概率为 Pr(tag | wi) = softmax(s(hi)) 其中 Pr(tag | wi) ∈ Rp。 在这项工作中，我们仅将 softmax 方法用于实体分类 (EC) 任务（类似于 NER），其中假设边界已给定，我们只需要预测每个标记的实体类型（例如，PER）。  CRF 方法用于 NER 任务，包括实体类型和边界识别。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Joint%20recognition%20and%20relation%20extraction/figure/formula_3.png)

在 softmax 方法中，我们在预测时以贪婪的方式将实体类型分配给令牌（即，所选标签只是所有可能标签集中得分最高的标签）。 尽管假设独立的标签分布有利于实体分类任务（例如，词性标注），但当标签之间存在强依赖性时，情况并非如此。 具体来说，在 NER 中，BIO 标记方案强制执行了几个限制（例如，B-LOC 不能跟在 I-PER 之后）。 即使 BiLSTM 捕获了有关相邻单词的信息，softmax 方法也允许进行局部决策（即，对于每个标记 wi 的标签）。 尽管如此，对于特定令牌的标签决策，不考虑相邻标签。 例如，在实体“John Smith”中，将“Smith”标记为 PER 有助于确定“John”是 B-PER。 为此，对于 NER，我们使用线性链 CRF，类似于 Lample 等人。  （2016 年），其中报告了使用 CRF 时约 1% F1 NER 点的改进。 在我们的例子中，通过使用 CRF，我们还报告了 1% 的整体性能改进，如表 2 所示（参见第 5.2 节）。 假设词向量 w、得分向量序列 s(e) 1 , ..., s(e) n 和标签预测向量 y(e) 1 , ..., y(e) n ，线性 -chain CRF 分数定义为：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Joint%20recognition%20and%20relation%20extraction/figure/formula_4.png)

我们应用 Viterbi 来获得得分最高的标签序列 ˆy(e)。 我们通过最小化交叉熵损失 LNER 来训练 softmax（用于 EC 任务）和 CRF 层（用于 NER）。 我们还通过学习标签嵌入使用实体标签作为我们关系提取层的输入，这是由 Miwa & Bansal (2016) 推动的，其中报告了 2% F1 的改进（使用标签嵌入）。 在我们的例子中，标签嵌入导致 F1 分数增加 1%，如表 2 所示（参见第 5.2 节）。下一层的输入是双重的：LSTM 的输出状态和学习的标签嵌入表示，编码了命名实体知识可用于关系提取的直觉。 在训练期间，我们使用黄金实体标签，而在预测时，我们使用预测的实体标签作为下一层的输入。 下一层的输入是隐藏 LSTM 状态 hi 与标记 wi 的标签嵌入 gi 的串联：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Joint%20recognition%20and%20relation%20extraction/figure/formula_5.png)

#### 3.4 关系提取作为多头选择

在本小节中，我们描述了关系提取任务，该任务被表述为一个多头选择问题（Zhang 等人，2017 年；Bekoulis 等人，2018 年）。 在我们方法的一般表述中，每个标记 wi 可以有多个头（即与其他标记的多个关系）。 我们预测元组 (ˆyi, ˆci)，其中 ˆyi 是正面的向量，而 ˆci 是每个标记 wi 的对应关系的向量。 这与之前的依赖解析方法（Zhang et al., 2017）的标准头部选择不同，因为（i）它被扩展到预测多个头部并且（ii）头部和关系的决定是联合采取的（即， 而不是首先预测头部，然后在下一步中通过使用额外的分类器来预测关系）。 给定一个标记序列 w 和一组关系标签 R 作为输入，我们的目标是为每个标记 wi 识别，i ∈ {0, ..., n} 最可能的头的向量 ˆyi ⊆ w 和 最可能的对应关系标签 ˆri ⊆ R。我们计算标记 wi 和 wj 之间的分数给定标签 rk 如下：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Joint%20recognition%20and%20relation%20extraction/figure/formula_6.png)

其中上标 (r) 用于关系任务的表示法，f(·) 是元素激活函数（即 relu，tanh），V (r) ∈ Rl，U (r) ∈ Rl×(2d+  b), W (r) ∈ Rl×(2d+b), b(r) ∈ Rl, d 是 LSTM 的隐藏大小，b 是标签嵌入的大小，l 是层宽。 我们定义

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Joint%20recognition%20and%20relation%20extraction/figure/formula_7.png)

是标记 wj 被选为标记 wi 的头部的概率，它们之间的关系标签为 rk，其中 σ(.) 代表 sigmoid 函数。 我们在训练期间最小化交叉熵损失 Lrel：

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Joint%20recognition%20and%20relation%20extraction/figure/formula_8.png)

其中 yi ⊆ w 和 ri ⊆ R 是头部的真实向量和 wi 的关联关系标签，m 是 wi 的关系（头部）的数量。 训练后，我们保持头 yi 和关系标签 ri 的组合超过基于等式中定义的估计联合概率的阈值。  (7). 与之前关于联合模型的工作 (Katiyar & Cardie, 2017) 不同，我们能够预测多个关系，将类视为独立而不是相互排斥的（不同类的概率总和不一定为 1）。 对于联合实体和关系提取任务，我们将最终目标计算为 LNER + Lrel。

#### 3.5 埃德蒙兹算法

我们的模型能够同时提取实体提及和它们之间的关系。 为了证明我们模型的有效性和通用性，我们还在最近推出的荷兰房地产分类 (DREC) 数据集（Bekoulis 等人，2017 年）上对其进行了测试，其中实体需要形成树状结构。 通过使用阈值推理，不能保证关系的树结构。 因此，我们应该对我们的模型实施树结构约束。 为此，我们使用 Edmonds 的有向图最大生成树算法 (Chu & Liu, 1965; Edmonds, 1967) 对系统的输出进行后处理。 构建了一个完全连接的有向图 G = (V, E)，其中顶点 V 表示已识别实体的最后一个标记（由 NER 预测），边 E 表示以其得分作为权重的最高得分关系。  Edmonds 算法适用于尚未通过阈值推理形成树的情况。

## 4 实验

#### 4.1 数据集和评估指标

我们对四个数据集进行了实验：（i）自动内容提取，ACE04（Doddington 等人，2004 年），（ii）药物不良事件，ADE（Gurulingappa 等人，2012b），(iii) Dutch Real Estate Classifieds, DREC (Bekoulis et al., 2017) 和 (iv) 带有实体和关系识别语料库的 CoNLL’04 数据集 (Roth & Yih, 2004)。 我们的代码在我们的 github codebase.2 中可用

ACE04：有七种主要实体类型，即人（PER）、组织（ORG）、地理实体（GPE）、位置（LOC）、设施（FAC）、武器（WEA）和车辆（VEH）。 此外，该数据集定义了七种关系类型：Physical (PHYS)、PersonSocial (PER-SOC)、Employment-Membership-Subsidiary (EMP-ORG)、Agent-Artifact (ART)、PER-ORG affiliation (Other-AFF)、GPE 隶属关系（GPE-AFF）和话语（DISC）。
   我们遵循 Li & Ji (2014) 和 Miwa & Bansal (2016) 的交叉验证设置。
   我们移除了 DISC 并对 bnews 和 nwire 子集（348 个文档）进行了 5 折交叉验证。 我们从 Miwa 的 github 代码库中获得了预处理脚本。3 我们使用实体和关系的微观 F1 分数、精确度和召回率来衡量我们系统的性能。 当实体类型和头部区域正确时，我们将实体视为正确的。 当类型和参数实体正确时，我们将关系视为正确的，类似于 Miwa & Bansal (2016) 和 Katiyar & Cardie (2017)。 我们将这种类型的评估称为严格的。4 我们在随机选择的验证集上为每个折叠选择最佳超参数值，从训练集（数据的 15%）中选择，因为在 Miwa 和 Bansal 的作品（2016 年）。

CoNLL04：数据集中有四种实体类型（Location、Organization、Person 和其他）和五种关系类型（Kill、Live in、Losting in、OrgBased in 和 Work for）。 我们使用 Gupta 等人定义的分割。  (2016) 和 Adel & Schüutze (2017)。 该数据集包含 910 个训练实例，243 个用于验证，288 个用于测试。5 我们通过计算测试集的 F1 分数来衡量性能。 我们采用两种评估设置来与以前的工作进行比较。 具体来说，我们执行 EC 任务，假设实体边界与 Gupta 等人相似。  (2016) 和 Adel & 14 Schüutze (2017)。 为了获得可比较的结果，我们在计算 EC 分数时省略了实体类“其他”。 假设边界是给定的，如果至少一个包含令牌类型是正确的，我们将多令牌实体评分为正确； 当关系的类型和参数实体都正确时，关系是正确的。 我们报告 EC 和 RE 的宏观平均 F1 分数，以获得与先前研究相当的结果。 此外，我们执行实际的 NER 评估，而不仅仅是 EC，使用严格的评估指标报告结果。

DREC：数据集包含 2,318 个分类，如 Bekoulis 等人的工作中所述。  (2018)。 有 9 种实体类型：Neighborhood、Floor、Extra building、Subspace、Invalid、Field、Other、Space 和 Property。 此外，还有两个关系类 Part-of 和 Equivalent。 目标是从分类广告中识别房产的重要实体（例如，楼层、空间），并将它们组织成树形格式，以获得房产的结构化描述。 对于评估，我们使用 70% 的训练集，15% 的验证集和 15% 的测试集，与 Bekoulis 等人定义的相同分割。  (2018)。我们通过计算测试集上的 F1 分数来衡量性能。 为了将我们的结果与之前的工作（Bekoulis 等人，2018 年）进行比较，我们使用了边界评估设置。 在此设置中，如果实体的边界正确，我们将实体视为正确。 当关系正确且参数实体都正确时，关系是正确的。 此外，我们使用严格的评估报告结果以供将来参考。

ADE：该数据集中有两种类型的实体（药物和疾病），任务的目的是识别实体类型并将每种药物与疾病（药物不良事件）相关联。 总共有 6,821 个句子，与之前的工作（Li et al., 2016, 2017）相似，我们删除了约 130 个与重叠实体的关系（例如，“lithium”是一种与“lithium intoxication”相关的药物）。 由于没有官方数据集，我们使用 10 折交叉验证来评估我们的模型，其中 10% 的数据用作验证，10% 的数据用作类似于 Li 等人的测试集。  (2017)。 最终结果以 F1 指标显示为跨折叠的宏观平均值。 该数据集由 10,652 个实体和 6,682 个关系组成。 我们使用严格的评估指标报告与之前在该数据集上的工作类似的结果。

#### 4.2 词嵌入

我们使用先前工作中使用的预训练 word2vec 嵌入，以便为我们的模型保留相同的输入并获得不受输入嵌入影响的可比较结果。 具体来说，我们将 Miwa & Bansal (2016) 工作中使用的 200 维词嵌入用于在维基百科上训练的 ACE04 数据集6。 我们获得了 Adel & Sch¨utze (2017)5 使用的 50 维词嵌入，也在维基百科上为 CoNLL04 语料库训练。 我们使用 Bekoulis 等人使用的 128 维 word2vec 嵌入。  (2018) 为 DREC 数据集训练了大量 887k 荷兰房地产广告7。 最后，对于 ADE 数据集，我们使用了 Li 等人使用的 200 维嵌入。  (2017) 并结合 PubMed 和 PMC 文本以及从英语维基百科中提取的文本进行训练 (Moen & Ananiadou, 2013)8。

#### 4.3 超参数和实现细节

我们通过使用 Python 和 TensorFlow 机器学习库（Abadi 等，2016）开发了我们的联合模型。 使用 Adam 优化器 (Kingma & Ba, 2015) 进行训练，学习率为 10-3。 我们将 LSTM 的大小固定为 d = 64，将神经网络的层宽固定为 l = 64（对于实体和关系评分层）。 我们使用 dropout (Srivastava et al., 2014) 来规范我们的网络。  Dropout 应用于输入嵌入和两个任务的隐藏层之间。 已经应用了不同的辍学率，但已使用每个数据集的最佳辍学值（0.2 到 0.4）。 基于字符的 LSTM 的隐藏维度是 25（每个方向）。 我们还将所有数据集的标签嵌入固定为 b = 25，除了 CoNLL04，其中标签嵌入没有用处，因此未使用。 我们试验了 tanh 和 relu 激活函数（回想一下，这是模型描述中的函数 f(·)）。 我们仅在 ACE04 中使用 relu 激活，在所有其他数据集中使用 tanh。 我们采用基于验证集的提前停止技术。 在本研究中检查的所有数据集中，根据数据集的大小，我们在 60 到 200 个 epoch 后获得了最佳超参数。 我们根据验证集中的结果选择最佳时期。有关每个超参数对模型性能影响的更多详细信息，请参阅附录。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Joint%20recognition%20and%20relation%20extraction/figure/table_1.png)

表 1：我们的方法（多头）与最先进的方法在 ACE04、CoNLL04、DREC 和 ADE 数据集上的比较。 模型：(i) 多头 + E（模型 + Edmond 算法产生树结构输出），（ii）单头（模型预测每个令牌只有一个头）和（iii）多头 EC（ 该模型仅预测实体类（假设给定边界）是适用于每个数据集和评估的多头模型的轻微变化。  ? 和 ? 符号表示模型是否依赖任何手工制作的功能或附加工具。 请注意，我们模型的所有变体都不依赖于任何附加功能。 我们在这里包括不同的评估类型（严格、宽松和边界），以便能够将我们的结果与以前的研究进行比较。 最后，我们报告了两个子任务的精度、召回率、F1 以及整体 F1 的结果，对两个子任务求平均值。 粗体条目表示仅考虑自动学习特征的模型中的最佳结果。

## 5 结果与讨论

#### 5.1 结论

在表 1 中，我们展示了我们的分析结果。 第一列表示考虑的数据集。 在第二列中，我们表示应用的模型（即之前的工作和提议的模型）。 提出的模型如下：(i) multi-head 是提出的模型，带有用于 NER 的 CRF 层和用于多头预测的 sigmoid 损失，(ii) multi-head+E 是增加了 Edmonds 算法的建议模型 为了保证 DREC 数据集的树结构输出，（iii）单头是建议的方法，但它使用 softmax 损失而不是 sigmoid 预测每个令牌只有一个头，并且（iv）多头 EC 是建议的 假设边界给定，使用 softmax 预测实体类的方法，以及多头选择的 sigmoid 损失。 表 1 还指出了不同的设置是否包括手工制作的特征或源自 NLP 工具的特征（例如，词性标注器、依赖解析器）。 我们使用 ? 符号表示该模型包括这种附加功能和 ? 符号表示该模型仅基于自动提取的特征。 请注意，我们模型的所有变体都不依赖于任何附加功能。 在下一列中，我们声明了为每个实验进行的评估类型。 我们在这里包括不同的评估类型，以便能够将我们的结果与以前的研究进行比较。 具体来说，我们使用三种评估类型，即：

(i) 严格：如果实体的边界和类型都正确，则该实体被认为是正确的； 当关系的类型和参数实体都正确时，关系是正确的，

(ii) 边界：如果实体的边界是正确的（不考虑实体类型），则该实体被认为是正确的； 当关系的类型和参数实体都正确并且

(iii) 宽松：假设边界是给定的，如果至少一个包含令牌类型是正确的，我们将多令牌实体评分为正确； 当关系的类型和参数实体都正确时，关系是正确的。

在接下来的三列中，我们展示了实体识别任务（Precision、Recall、F1）的结果，然后（在随后的三列中）展示了关系提取任务（Precision、Recall、F1）的结果。 最后，在最后一列中，我们报告了一个额外的 F1 度量，它是两个子任务的平均 F1 性能。 我们在表 1 中用粗体标记，在那些仅使用自动提取特征的模型中，每个数据集的最佳结果。

考虑到 ACE04 中的结果，我们观察到我们的模型在两个任务中都比 Katiyar & Cardie (2017) 的模型好 2%。 这种改进可以通过使用多头选择方法来解释，该方法可以自然地捕获多个关系并将它们建模为多标签问题。 与 Katiyar & Cardie (2017) 的工作不同，类别概率的总和不一定为 1，因为类别被认为是独立的。 此外，我们使用 CRF 层对 NER 任务进行建模，以捕获顺序标记之间的依赖关系。 最后，我们通过使用字符级嵌入获得更有效的词表示。 另一方面，与 Miwa & Bansal (2016) 相比，我们的模型在合理的范围内执行（NER 任务约为 0.5%，RE 任务约为 1%）。 这种差异的原因是 Miwa & Bansal (2016) 的模型依赖于词性标注和依赖解析导出的句法特征。 然而，这种功能依赖于 NLP 工具，这些工具对于各种语言和上下文并不总是准确的。 例如，Li 等人的工作采用了相同的模型。  (2017) 对于 ADE 生物医学数据集，在这个数据集中，我们的模型报告 RE 任务有超过 3% 的改进。 这表明我们的模型能够生成自动提取的特征，这些特征在所有上下文（例如，新闻、生物医学）中都表现得相当好。

对于 CoNLL04 数据集，有两种不同的评估设置，即宽松和严格。 在宽松的设置中，假设实体的边界是给定的，我们执行 EC 任务而不是 NER。 我们采用这种设置来产生与之前研究相当的结果（Gupta 等人，2016 年；Adel & Schüutze，2017 年）。与 Adel & Schüutze (2017) 类似，我们展示了单个模型的结果，没有集成。 我们观察到，我们的模型在很大程度上优于所有以前不依赖复杂手工制作特征的模型（两项任务均超过 4%）。 与之前考虑实体对以获得实体类型和对应关系的研究不同，我们一次对整个句子进行建模。 这样，我们的方法能够直接推断一个句子的所有实体和关系，并从它们可能的交互中受益，这些交互在对每个实体对单独执行训练时无法建模，一次一个。 在相同的设置中，我们还报告了 Gupta 等人的结果。  （2016）他们使用来自 NLP 工具的多个复杂的手工特征。 我们的模型在 EC 任务上的表现稍好一些，并且在整体 F1 分数方面的差距在 1% 以内。 整体性能的差异是由于我们的模型仅使用自动生成的特征。 我们还报告了执行 NER（即预测实体类型和边界）并使用严格评估措施进行评估的同一数据集的结果，类似于 Miwa 和 Sasaki（2014）。我们的结果不能与 Miwa & Sasaki (2014) 的工作直接比较，因为我们使用了 Gupta 等人提供的分割。  (2016)。 然而，在这种情况下，我们将 Miwa & Sasaki (2014) 的结果作为参考。 我们报告总体 F1 分数提高了约 2%，这表明与基于特征的方法相比，我们的神经模型能够提取更多信息表示。

我们还报告了 DREC 数据集的结果，具有两种不同的评估设置。具体来说，我们使用边界和严格设置。 我们转换了 Bekoulis 等人之前的结果。  (2018) 的边界设置使它们与我们的模型具有可比性，因为在他们的工作中，他们报告了基于令牌的 F1 分数，这不是关系提取问题中的常见评估指标。 此外，在他们的工作中，他们专注于仅识别实体的边界，而不是类型（例如，楼层、空间）。 在边界评估中，我们对这两个任务都实现了约 3% 的改进。这是因为它们的二次评分层有利于 RE 任务，但使 NER 复杂化，通常将其建模为序列标记任务。 此外，我们使用大多数相关工作中使用的严格评估来报告结果。 使用每个实体只有一个头部的先验知识，我们可以简化我们的模型并每次只预测一个头部（即使用 softmax 损失）。 单头和多头模型之间的差异很小（两个任务均小于 0.1%）。 这表明我们的模型（多头）可以适应各种环境，即使设置是单头（就应用而言，因此也适用于训练和测试数据）。

最后，我们在 ADE 数据集上将我们的模型与之前的工作 (Li et al., 2016, 2017) 进行比较。 之前的模型（Li 等人，2016 年、2017 年）都使用手工制作的特征或源自 NLP 工具的特征。 然而，使用严格的评估指标，我们的模型能够胜过这两个模型。 我们报告说，NER 和 RE 任务分别提高了约 2% 和约 3%。 李等人的工作。  (2017) 类似于 Miwa & Bansal (2016)，并且强烈依赖依赖解析器来提取句法信息。 从我们的模型中获得更好结果的一个可能解释是，使用外部工具获得的预先计算的句法信息要么不那么准确，要么对生物医学数据不重要。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NLP/%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/%E5%A4%8D%E6%9D%82%E8%AF%AD%E5%A2%83%E4%B8%8B%E7%9A%84%E5%AE%9E%E4%BD%93%E5%85%B3%E7%B3%BB%E6%8A%BD%E5%8F%96/2.%E8%A1%A8%E5%A1%AB%E5%85%85/Joint%20recognition%20and%20relation%20extraction/figure/table_2.png)

表 2：ACE04 测试数据集上的消融测试。

#### 5.2 特征贡献分析

我们对表 2 中报告的 ACE04 数据集进行消融测试，以分析我们联合模型各个部分的有效性。 当我们移除标签嵌入层并仅使用 LSTM 隐藏状态作为 RE 任务的输入时，RE 任务的性能下降（就 F1 分数而言约为 1%）。 这表明 NER 标签正如预期的那样，为 RE 组件提供了有意义的信息。

删除字符嵌入也会以相对较大的幅度降低 NER（~1%）和 RE（~2%）任务的性能。 这说明通过字符表示组合单词是有效的，我们的方法受益于附加信息，例如标记中的大写字母、后缀和前缀（即其字符序列）。

最后，我们通过移除 CRF 损失层并用 softmax 代替它来对 NER 任务进行实验。 假设标签的独立分布（即 softmax）导致 NER 模块的 F1 性能略有下降，RE 任务的性能下降约 2%。 发生这种情况是因为 CRF 损失能够捕获数据集中存在的强标签依赖性（例如，I-LOC 不能遵循 B-PER），而不是仅仅假设每个令牌的标签决策独立于相邻的标签决策 令牌。

#### 6 总结

在这项工作中，我们提出了一个联合神经模型来同时从文本数据中提取实体和关系。 我们的模型包括一个用于实体识别任务的 CRF 层和一个用于关系提取任务的 sigmoid 层。 具体来说，我们将关系提取任务建模为一个多头选择问题，因为一个实体可以有多个关系。 此任务的先前模型严重依赖外部 NLP 工具（即 POS 标记器、依赖解析器）。 因此，这些模型的性能受提取特征的准确性影响。 与之前的研究不同，我们的模型生成自动生成的特征，而不是依赖手工制作的特征或现有的 NLP 工具。 鉴于其独立于此类 NLP 或其他特征生成工具，我们的方法可以轻松应用于任何语言和上下文。 我们通过进行大规模的实验研究来证明我们方法的有效性。 我们的模型能够胜过自动生成特征的神经方法，而结果与基于特征的神经网络方法相比略有相似（或有时更好）。

作为未来的工作，我们的目标是探索实体识别模块的实体预训练的有效性。 这种方法在 Miwa & Bansal (2016) 的工作中已被证明对实体和关系提取模块都是有益的。 此外，我们正计划探索一种减少二次关系评分层计算量的方法。 例如，一种直接的方法是在 sigmoid 层中仅使用已被识别为实体的令牌。



















