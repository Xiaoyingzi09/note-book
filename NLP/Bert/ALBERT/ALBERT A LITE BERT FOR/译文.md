# ALBERT：用于语言表示自我监督学习的 Lite BERT

## 摘要

在预训练自然语言表示时==增加模型大小==通常会提高下游任务的性能。 然而，在某些时候，由于 ==GPU/TPU 内存限制==和更长的训练时间，进一步增加模型变得更加困难。 为了解决这些问题，我们提出了==两种参数减少技术==来降低内存消耗并提高 BERT 的训练速度（Devlin 等人，2019）。 综合经验证据表明，与原始 BERT 相比，我们提出的方法导致模型的==扩展性更好==。 我们还使用==自监督损失==，专注于对==句间连贯性建模==，并表明它始终如一地帮助具有多句输入的下游任务。 因此，与 BERT-large 相比，我们的最佳模型在 GLUE、RACE 和 SQuAD 基准测试中建立了最新的最新结果，同时具有==更少的参数==。 代码和预训练模型可从 https://github.com/google-research/ALBERT 获得。



## 1 前言

全网络预训练（Dai & Le, 2015; Radford et al., 2018; Devlin et al., 2019; Howard & Ruder, 2018）在语言表征学习方面取得了一系列突破。 许多重要的 NLP 任务，包括那些训练数据有限的任务，都从这些预训练模型中受益匪浅。 这些突破中最引人注目的迹象之一是机器在为中国中学和高中英语考试设计的阅读理解任务 RACE 测试（Lai 等人，2017 年）中的性能演变：最初描述了 任务并制定建模挑战报告，然后达到 44.1% 的最先进机器精度； 最新发布的结果报告他们的模型性能为 83.2%（Liu 等人，2019）； 我们在此展示的工作将其推高至 89.4%，惊人的 45.3% 提高主要归功于我们目前构建高性能预训练语言表示的能力。

这些改进的证据表明，大型网络对于实现最先进的性能至关重要（Devlin 等人，2019 年；Radford 等人，2019 年）。 预训练大型模型并将其提炼成较小的模型（Sun 等人，2019 年；Turc 等人，2019 年）已成为实际应用的常见做法。 鉴于模型大小的重要性，我们会问：<em>拥有更好的 NLP 模型和拥有更大的模型一样容易吗？</em>

回答这个问题的一个障碍是可用硬件的==内存限制==。 鉴于当前最先进的模型通常具有数亿甚至数十亿个参数，因此在我们尝试扩展模型时很容易遇到这些限制。 在分布式训练中，==训练速度==也会受到显着影响，因为==通信开销==与模型中的==参数数量==成==正比==。

上述问题的现有解决方案包括模型并行化（Shazeer 等人，2018 年；Shoeybi 等人，2019 年）和智能内存管理（Chen 等人，2016 年；Gomez 等人，2017 年）。

这些解决方案解决了内存限制问题，但没有解决通信开销。 在本文中，我们通过设计参数明显少于传统 BERT 架构的 Lite BERT (ALBERT) 架构来解决上述所有问题。

ALBERT 结合了两种参数减少技术，可以消除扩展预训练模型的主要障碍。 第一个是分解嵌入参数化。 通过将大词汇嵌入矩阵分解为两个小矩阵，我们将隐藏层的大小与词汇嵌入的大小分开。 这种分离使得在不显着增加词汇嵌入的参数大小的情况下更容易增加隐藏大小。 第二种技术是跨层参数共享。 这种技术可以防止参数随着网络深度的增加而增长。 这两种技术都在不严重损害性能的情况下显着减少了 BERT 的参数数量，从而提高了参数效率。 类似于 BERT-large 的 ALBERT 配置的参数减少了 18 倍，训练速度提高了约 1.7 倍。参数减少技术还充当一种正则化形式，可以稳定训练并有助于泛化。

为了进一步提高 ALBERT 的性能，我们还为句子顺序预测 (SOP) 引入了自监督损失。  SOP 主要侧重于句间连贯性，旨在解决原始 BERT 中提出的下一句预测 (NSP) 损失的无效性（Yang 等人，2019 年；Liu 等人，2019 年）。

由于这些设计决策，我们能够扩展到更大的 ALBERT 配置，这些配置仍然比 BERT-large 具有更少的参数，但实现了显着更好的性能。 我们在著名的 GLUE、SQuAD 和 RACE 自然语言理解基准测试中建立了最新的最新结果。 具体来说，我们将 RACE 准确率提高到 89.4%，将 GLUE 基准提高到 89.4，将 SQuAD 2.0 的 F1 分数提高到 92.2。



## 2 相关工作

### 2.1 扩大自然语言的表征学习

自然语言的学习表征已被证明可用于广泛的 NLP 任务并已被广泛采用（Mikolov 等，2013；Le & Mikolov，2014；Dai & Le，2015；Peters 等，2018；  Devlin 等人，2019 年；Radford 等人，2018 年；2019 年）。 过去两年中最显着的变化之一是从预训练词嵌入的转变，无论是标准的（Mikolov 等人，2013 年；Pennington 等人，2014 年）还是上下文化的（McCann 等人，2017 年；Peters 等人）  al., 2018)，到全网络预训练，然后是针对特定任务的微调（Dai & Le, 2015; Radford et al., 2018; Devlin et al., 2019）。 在这方面的工作中，通常表明更大的模型尺寸可以提高性能。 例如，德夫林等人。  (2019) 表明，在三个选定的自然语言理解任务中，使用更大的隐藏尺寸、更多的隐藏层和更多的注意力头总是会带来更好的性能。 然而，它们在隐藏大小 1024 处停止，大概是因为模型大小和计算成本问题。

由于计算限制，很难用大型模型进行实验，尤其是在 GPU/TPU 内存限制方面。 鉴于当前最先进的模型通常有数亿甚至数十亿个参数，我们很容易达到内存限制。 为了解决这个问题，陈等人。  (2016) 提出了一种称为梯度检查点的方法，以额外的前向传递为代价来减少次线性的内存需求。 戈麦斯等人。  (2017) 提出了一种从下一层重建每一层激活的方法，这样它们就不需要存储中间激活。 这两种方法都以速度为代价减少了内存消耗。 拉斐尔等人。  (2019) 提出使用模型并行化来训练一个巨型模型。 相比之下，我们参数减少的技术减少了内存消耗并提高了训练速度。

### 2.2 跨层参数共享

之前已经使用 Transformer 架构（Vaswani 等人，2017 年）探索了跨层共享参数的想法，但这项先前的工作侧重于标准编码器解码器任务的训练，而不是预训练/微调设置。 与我们的观察不同，Dehghani 等人。  (2018) 表明，与标准转换器相比，具有跨层参数共享的网络（Universal Transformer，UT）在语言建模和主谓一致性方面获得了更好的性能。 最近，白等人。  (2019) 提出了一种用于变压器网络的深度均衡模型 (DQE)，并表明 DQE 可以达到某一层的输入嵌入和输出嵌入保持不变的平衡点。 我们的观察表明，我们的嵌入是振荡而不是收敛。 郝等人。  (2019) 将参数共享变压器与标准变压器相结合，进一步增加了标准变压器的参数数量。

### 2.3 句子排序目标 SENTENCE ORDERING OBJECTIVES

ALBERT 使用基于预测两个连续文本段的顺序的预训练损失。 一些研究人员已经尝试了与话语连贯性类似的预训练目标。 话语中的连贯性和内聚性已被广泛研究，并且已经确定了许多连接相邻文本片段的现象（Hobbs，1979；Halliday & Hasan，1976；Grosz 等，1995）。 在实践中发现有效的大多数目标都非常简单。Skipthought (Kiros et al., 2015) 和 FastSent (Hill et al., 2016) 句子嵌入是通过使用句子的编码来预测相邻句子中的单词来学习的。 句子嵌入学习的其他目标包括预测未来句子而不仅仅是邻居（Gan 等人，2017）和预测显式话语标记（Jernite 等人，2017 年；Nie 等人，2019 年）。 我们的损失与 Jernite 等人的句子排序目标最相似。  （2017），其中学习句子嵌入以确定两个连续句子的顺序。 然而，与上述大部分工作不同，我们的损失是在文本段而不是句子上定义的。  BERT（Devlin 等人，2019 年）使用基于预测一对中的第二个片段是否已与另一个文档中的片段交换的损失。 我们在实验中与这种损失进行比较，发现句子排序是一项更具挑战性的预训练任务，对某些下游任务更有用。 在我们工作的同时，Wang 等人。  (2019) 也尝试预测两个连续文本段的顺序，但他们在三向分类任务中将其与原始下一句预测相结合，而不是凭经验比较两者。

## 3 ALBERT的元素

在本节中，我们将介绍 ALBERT 的设计决策，并与原始 BERT 架构的相应配置进行量化比较（Devlin 等，2019）。

### 3.1 模型架构选择

ALBERT 架构的主干类似于 BERT，因为它使用具有 GELU 非线性的变压器编码器（Vaswani 等人，2017 年）（Hendrycks 和 Gimpel，2016 年）。 我们遵循 BERT 符号约定，将词汇嵌入大小表示为 E，编码器层数表示为 L，隐藏大小表示为 H。继 Devlin 等人之后。  (2019)，我们将前馈/滤波器大小设置为 4H，将注意力头的数量设置为 H/64。
  ALBERT 对 BERT 的设计选择做出了三个主要贡献。

**分解嵌入参数化。**

 在 BERT 以及后续建模改进中，例如 XLNet（Yang 等人，2019）和 RoBERTa（Liu 等人，2019 年），WordPiece 嵌入大小 E 与隐藏层大小 H 相关，即 E ≡ H  . 出于建模和实际原因，该决定似乎并不理想，如下所示。

从建模的角度来看，WordPiece 嵌入旨在学习与上下文无关的表示，而隐藏层嵌入旨在学习依赖于上下文的表示。正如上下文长度的实验所表明的那样（Liu 等人，2019），类 BERT 表示的力量来自于使用上下文来为学习这种依赖于上下文的表示提供信号。 因此，将 WordPiece 嵌入大小 E 与隐藏层大小 H 分开允许我们根据建模需要更有效地使用总模型参数，这决定了 H ≫ E。

从实际的角度来看，自然语言处理通常要求词汇量 V 较大。如果 E ≡ H，则增加 H 会增加嵌入矩阵的大小，其大小为V×E。 这很容易导致模型具有数十亿个参数，其中大部分仅在训练期间进行稀疏更新。

因此，对于 ALBERT，我们使用嵌入参数的因式分解，将它们分解为两个较小的矩阵。 我们不是将 one-hot 向量直接投影到大小为 H 的隐藏空间中，而是先将它们投影到大小为 E 的低维嵌入空间中，然后再将其投影到隐藏空间中。 通过使用这种分解，我们将嵌入参数从 O(V × H) 减少到 O(V × E + E × H)。 当 H ≫ E 时，这种参数减少很重要。我们选择对所有词片段使用相同的 E，因为与具有不同嵌入大小的全词嵌入相比，它们在文档中的分布更加均匀（Grave 等人（2017）  ; Baevski & Auli (2018); Dai et al. (2019) ) 对于不同的词很重要。

**跨层参数共享。**

 对于 ALBERT，我们提出跨层参数共享作为提高参数效率的另一种方式。 共享参数有多种方式，例如，仅跨层共享前馈网络（FFN）参数，或仅共享注意力参数。ALBERT 的默认决定是跨层共享所有参数。 除非另有说明，否则我们所有的实验都使用这个默认决定。 我们在第二节的实验中将这个设计决策与其他策略进行了比较4.5.

Dehghani 等人已经探索了类似的策略。  (2018) (Universal Transformer, UT) 和 Bai 等人。  (2019)（深度均衡模型，DQE）用于 Transformer 网络。 与我们的观察不同，Dehghani 等人。  (2018) 表明 UT 的性能优于普通 Transformer。 白等人。 (2019) 表明他们的 DQE 达到了一个平衡点，在这个点上，某个层的输入和输出嵌入保持不变。 我们对 L2 距离和余弦相似度的测量表明我们的嵌入是振荡而不是收敛。

![图1](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NoteBook/NLP/Bert/ALBERT/ALBERT%20A%20LITE%20BERT%20FOR/figure%201.png)

图 1：BERT-large 和 ALBERT-large 每一层的输入和输出嵌入的 L2 距离和余弦相似度（就度而言）。

图 1 显示了每层的输入和输出嵌入的 L2 距离和余弦相似度，使用 BERT-large 和 ALBERT-large 配置（见表 1）。 我们观察到 ALBERT 的层到层转换比 BERT 平滑得多。 这些结果表明，权重共享对稳定网络参数有影响。 尽管与 BERT 相比，这两个指标都有所下降，但即使在 24 层之后，它们也不会收敛到 0。 这表明 ALBERT 参数的解空间与 DQE 发现的有很大不同。

**句间连贯性损失。**

除了掩码语言建模 (MLM) 损失（Devlin 等人，2019 年）之外，BERT 还使用了一种称为下一句预测 (NSP) 的额外损失。  NSP是一种二元分类损失，用于预测原始文本中两个片段是否连续出现，如下：从训练语料中取连续片段创建正例； 反例是通过配对来自不同文档的片段来创建的； 正例和负例以相等的概率采样。  NSP 目标旨在提高下游任务的性能，例如自然语言推理，这些任务需要推理句子对之间的关系。 然而，随后的研究（Yang 等人，2019 年；Liu 等人，2019 年）发现 NSP 的影响不可靠并决定消除它，这一决定得到了多项任务下游任务性能改善的支持。

我们推测 NSP 效率低下的主要原因是与 MLM 相比，它作为一项任务缺乏难度。 按照公式，NSP 将主题预测和连贯性预测合并在一个任务中2。 然而，与一致性预测相比，主题预测更容易学习，并且与使用 MLM 损失学习的内容重叠更多。

![表1](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NoteBook/NLP/Bert/ALBERT/ALBERT%20A%20LITE%20BERT%20FOR/table%201.png)

表 1：本文分析的主要 BERT 和 ALBERT 模型的配置。

我们认为句间建模是语言理解的一个重要方面，但我们提出了一种主要基于连贯性的损失。 也就是说，对于 ALBERT，我们使用句序预测 (SOP) 损失，它避免了主题预测，而是专注于对句间连贯性进行建模。  SOP 损失使用与 BERT 相同的技术（来自同一文档的两个连续段）作为正例，而作为负例使用相同的两个连续段，但它们的顺序交换。 这迫使模型学习关于话语级别连贯性属性的更细粒度的区别。 正如我们在 Sec 中展示的那样。  4.6，结果证明 NSP 根本无法解决 SOP 任务（即，它最终学习了更容易的主题预测信号，并在 SOP 任务的随机基线级别上执行），而 SOP 可以在合理程度上解决 NSP 任务 ，大概是基于分析未对齐的相干线索。 因此，ALBERT 模型不断提高多句编码任务的下游任务性能。

### 3.2 模型设置

我们在表 1 中展示了具有可比超参数设置的 BERT 和 ALBERT 模型之间的差异。 由于上面讨论的设计选择，与相应的 BERT 模型相比，ALBERT 模型的参数大小要小得多。

例如，与 BERT-large 相比，ALBERT-large 的参数减少了大约 18 倍，分别是 18M 与 334M。  H = 2048 的 ALBERT-xlarge 配置只有 60M 参数，而 H = 4096 的 ALBERT-xxlarge 配置有 233M 参数，即大约 70% 的 BERTlarge 参数。 请注意，对于 ALBERT-xxlarge，我们主要报告 12 层网络的结果，因为 24 层网络（具有相同配置）获得相似的结果，但计算成本更高。

 参数效率的这种改进是 ALBERT 设计选择的最重要优势。 在我们量化这种优势之前，我们需要更详细地介绍我们的实验设置。



## 4 实验结果

### 4.1 实验设置

为了使比较尽可能有意义，我们遵循 BERT (Devlin et al., 2019) 设置，使用 BOOKCORPUS (Zhu et al., 2015) 和英文维基百科 (Devlin et al., 2019) 来预训练基线模型。 这两个语料库由大约 16GB 的未压缩文本组成。 我们将输入格式化为“[CLS] x1 [SEP] x2 [SEP]”，其中 x1 = x1,1, x1,2 · · · 和 x2 = x1,1, x1,2 · · · 是两个部分。 3 我们总是将最大输入长度限制为 512，并以 10% 的概率随机生成短于 512 的输入序列。 与 BERT 一样，我们使用 30,000 的词汇量，使用 SentencePiece（Kudo & Richardson，2018）和 XLNet（Yang 等，2019）进行标记。

我们使用 n-gram 掩码（Joshi 等，2019）为 MLM 目标生成掩码输入，随机选择每个 n-gram 掩码的长度。 长度 n 的概率由下式给出：

​                                              $p(n) =\frac{1/n}{\sum_{k=1}^N1/k}$

我们将 n-gram（即 n）的最大长度设置为 3（即 MLM 目标最多可以包含 3-gram 的完整单词，例如“白宫通讯员”）。

所有模型更新都使用 4096 的批量大小和学习率为 0.00176 的 LAMB 优化器（You 等，2019）。 除非另有说明，否则我们将所有模型训练 125,000 步。 训练是在 Cloud TPU V3 上完成的。 用于训练的 TPU 数量从 64 到 512 不等，具体取决于模型大小。

除非另有说明，本节中描述的实验设置用于我们自己的所有 BERT 版本以及 ALBERT 模型。

### 4.2 评估基准

#### 4.2.1 内在评估

为了监控训练进度，我们根据 SQuAD 和 RACE 的开发集创建了一个开发集，使用与第 2 节相同的程序。  4.1. 我们报告了 MLM 和句子分类任务的准确性。 请注意，我们仅使用此集合来检查模型的收敛情况； 它的使用方式不会影响任何下游评估的性能，例如通过模型选择。

#### 4.2.2 下游评估

继杨等人。  (2019) 和 Liu 等人。  (2019)，我们在三个流行的基准上评估我们的模型：通用语言理解评估 (GLUE) 基准（Wang 等人，2018 年）、斯坦福问答数据集的两个版本（SQuAD；Rajpurkar 等人，2016 年；2018 年）  )，以及来自考试的阅读理解 (RACE) 数据集（Lai 等人，2017 年）。 为完整起见，我们在附录 A.3 中提供了这些基准的描述。 与 (Liu et al., 2019) 中一样，我们在开发集上执行提前停止，我们报告了除基于任务排行榜的最终比较之外的所有比较，我们还报告了测试集结果。 对于在开发集上有很大差异的 GLUE 数据集，我们报告超过 5 次运行的中位数。

### 4.3 BERT 和 ALBERT 的总体比较

我们现在已准备好量化第 2 节中描述的设计选择的影响。  3、特别是参数效率方面的。 参数效率的提高展示了 ALBERT 设计选择的最重要优势，如表 2 所示：仅 BERT-large 参数的 70% 左右，ALBERT-xxlarge 就实现了比 BERT-large 的显着改进，这通过开发差异来衡量 为几个有代表性的下游任务设置分数：SQuAD v1.1 (+1.9%)、SQuAD v2.0 (+3.1%)、MNLI (+1.4%)、SST-2 (+2.2%) 和 RACE (+8.4%)  ）。

另一个有趣的观察是在相同训练配置（相同数量的 TPU）下训练时的数据吞吐量速度。 由于较少的通信和较少的计算，与相应的 BERT 模型相比，ALBERT 模型具有更高的数据吞吐量。 如果我们使用 BERT-large 作为基线，我们观察到 ALBERT-large 在迭代数据时大约快 1.7 倍，而 ALBERT-xxlarge 由于更大的结构而慢大约 3 倍。

接下来，我们进行消融实验，量化 ALBERT 的每个设计选择的个人贡献。

### 4.4 因子嵌入参数化

表 3 显示了使用基于 ALBERT 的配置设置（参见表 1），使用相同的一组代表性下游任务更改词汇嵌入大小 E 的效果。 在非共享条件下（BERT 风格），更大的嵌入尺寸会提供更好的性能，但不会太多。 在全共享条件下（ALBERT 风格），大小为 128 的嵌入似乎是最好的。 基于这些结果，我们在未来的所有设置中使用嵌入大小 E = 128，作为进一步扩展的必要步骤。

![表2](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NoteBook/NLP/Bert/ALBERT/ALBERT%20A%20LITE%20BERT%20FOR/table%202.png)

表 2：在 BOOKCORPUS 和 Wikipedia 上预训练 125k 步的模型的开发集结果。在这里和其他地方，Avg 列是通过对其左侧下游任务的分数求平均值来计算的（首先对每个 SQuAD 的 F1 和 EM 两个数字求平均值）。

![表3](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NoteBook/NLP/Bert/ALBERT/ALBERT%20A%20LITE%20BERT%20FOR/table%203.png)

表 3：词汇嵌入大小对 ALBERT-base 性能的影响。

### 4.5 跨层参数共享

表 4 展示了各种跨层参数共享策略的实验，使用具有两种嵌入大小（E = 768 和 E = 128）的基于 ALBERT 的配置（表 1）。 我们比较了全共享策略（ALBERT 风格）、非共享策略（BERT 风格）和仅共享注意力参数（但不共享 FNN 参数）或仅共享 FFN 参数的中间策略（ 但不是注意力）。

全共享策略在这两种情况下都会损害性能，但与 E = 768（平均为 -2.5）相比，E = 128（平均为 1.5）的情况不那么严重。 此外，大部分性能下降似乎来自共享 FFN 层参数，而共享注意力参数在 E = 128（平均 +0.1）时没有下降，当 E = 768（-0.7 平均）。

还有其他跨层共享参数的策略。 例如，我们可以将 L 层分成 N 个大小为 M 的组，每个大小为 M 的组共享参数。 总的来说，我们的实验结果表明，组大小 M 越小，我们获得的性能就越好。 然而，减小组大小 M 也会显着增加整体参数的数量。 我们选择全共享策略作为我们的默认选择。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NoteBook/NLP/Bert/ALBERT/ALBERT%20A%20LITE%20BERT%20FOR/table%204.png)

表 4：跨层参数共享策略的影响，ALBERT-base 配置。

### 4.6 句子顺序预测 (SOP)

我们使用 ALBERTbase 配置直接比较了三个额外的句间损失的实验条件：无（XLNet 和 RoBERTa 风格）、NSP（BERT 风格）和 SOP（ALBERT 风格）。 结果如表 5 所示，包括内在（MLM、NSP 和 SOP 任务的准确性）和下游任务。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NoteBook/NLP/Bert/ALBERT/ALBERT%20A%20LITE%20BERT%20FOR/table%205.png)

表 5：句子预测损失、NSP 与 SOP 对内在和下游任务的影响。

内在任务的结果表明，NSP 损失不会给 SOP 任务带来任何判别力（准确率为 52.0%，类似于“None”条件下的随机猜测性能）。 这使我们能够得出结论，NSP 最终仅对主题转移进行建模。 相比之下，SOP loss 确实比较好地解决了 NSP 任务（78.9% 的准确率），而 SOP 任务甚至更好（86.5% 的准确率）。
   更重要的是，SOP 损失似乎持续提高了多句编码任务的下游任务性能（SQuAD1.1 大约 +1%，SQuAD2.0 +2%，RACE +1.7%），平均得分提高 大约 +1%。

### 4.7 如果我们训练相同的时间会怎样？

表 2 中的加速结果表明，BERT-large 的数据吞吐量比 ALBERT-xxlarge 高约 3.17 倍。 由于更长的训练通常会带来更好的性能，因此我们进行了比较，其中不控制数据吞吐量（训练步数），而是控制实际训练时间（即，让模型训练相同的小时数）  . 在表 6 中，我们比较了 BERT-large 模型在 400k 训练步骤（训练 34 小时后）后的性能，大致相当于使用 125k 训练步骤（32 小时训练）训练 ALBERT-xxlarge 模型所需的时间。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NoteBook/NLP/Bert/ALBERT/ALBERT%20A%20LITE%20BERT%20FOR/table%206.png)

表 6：控制训练时间的效果，BERT-large 与 ALBERT-xxlarge 配置。

经过大致相同的训练时间后，ALBERT-xxlarge 明显优于 BERT-large：在 Avg 上提高了 +1.5%，在 RACE 上的差异高达 +5.2%。

### 4.8 额外的训练数据和丢失效应 （DROPOUT EFFECTS）

到目前为止完成的实验仅使用 Wikipedia 和 BOOKCORPUS 数据集，如 (Devlin et al., 2019)。 在本节中，我们报告了对 XLNet（Yang 等人，2019）和 RoBERTa（Liu 等人，2019 年）使用的附加数据的影响的测量结果。
图 2a 绘制了在没有和有附加数据的两种条件下开发集 MLM 准确度，后一种条件显着提高。 我们还在表 7 中观察到下游任务的性能改进，除了 SQuAD 基准测试（基于维基百科，因此受到域外训练材料的负面影响）。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NoteBook/NLP/Bert/ALBERT/ALBERT%20A%20LITE%20BERT%20FOR/table%207.png)

表 7：使用 ALBERT-base 配置的额外训练数据的效果。

我们还注意到，即使经过 100 万步的训练，我们最大的模型仍然不会过度拟合它们的训练数据。 因此，我们决定移除 dropout 以进一步增加我们的模型容量。图 2b 中的图显示去除 dropout 显着提高了 MLM 精度。 在大约 100 万个训练步骤（表 8）上对 ALBERT-xxlarge 的中间评估也证实了去除 dropout 有助于下游任务。 有经验（Szegedy 等人，2017）和理论（Li 等人，2019 年）证据表明，卷积神经网络中批量归一化和 dropout 的组合可能会产生有害结果。 据我们所知，我们是第一个证明 dropout 会损害基于 Transformer 的大型模型的性能的人。 但是，ALBERT 的底层网络结构是transformer 的一个特例，需要进一步的实验，看看其他基于transformer 的架构是否会出现这种现象。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NoteBook/NLP/Bert/ALBERT/ALBERT%20A%20LITE%20BERT%20FOR/figure%202.png)

图 2：在训练过程中添加数据和去除 dropout 的效果。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NoteBook/NLP/Bert/ALBERT/ALBERT%20A%20LITE%20BERT%20FOR/table%208.png)

表 8：针对 ALBERT-xxlarge 配置测量的删除 dropout 的效果。

### 4.9 NLU 任务的最新技术水平

我们在本节中报告的结果利用了 Devlin 等人使用的训练数据。  (2019)，以及 Liu 等人使用的额外数据。  (2019) 和 Yang 等人。  (2019)。 我们在两种微调设置下报告了最先进的结果：单模型和集成。 在这两种设置中，我们只进行单任务微调4。 继刘等人。  (2019)，在开发集上，我们报告了五次运行的中值结果。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NoteBook/NLP/Bert/ALBERT/ALBERT%20A%20LITE%20BERT%20FOR/table%209.png)

表 9：GLUE 基准测试的最新结果。 对于单任务单模型结果，我们以 100 万步（与 RoBERTa 相当）和 150 万步报告 ALBERT。  ALBERT 集成使用经过 1M、1.5M 和其他步数训练的模型。

单模型 ALBERT 配置结合了所讨论的最佳性能设置：ALBERT-xxlarge 配置（表 1）使用组合的 MLM 和 SOP 损失，并且没有丢失。

根据开发集性能选择有助于最终集成模型的检查点； 此选择考虑的检查点数量范围为 6 到 17，具体取决于任务。 对于 GLUE（表 9）和 RACE（表 10）基准，我们对集成模型的模型预测进行平均，其中使用 12 层和 24 层架构从不同的训练步骤对候选模型进行微调。 对于 SQuAD（表 10），我们对具有多个概率的那些跨度的预测分数求平均值； 我们还平均了“无法回答”决定的分数。

单模型和集成结果都表明 ALBERT 显着提高了所有三个基准的最新技术水平，实现了 89.4 的 GLUE 分数、92.2 的 SQuAD 2.0 测试 F1 分数和 89.4 的 RACE 测试准确率。 后者似乎是一个特别强劲的改进，比 BERT（Devlin 等人，2019 年；Clark 等人，2019 年）高 17.4%，比 XLNet（Yang 等人，2019 年）高 7.6%， 比 RoBERTa (Liu et al., 2019) 高 6.2%，比 DCMI+ (Zhang et al., 2019) 高 5.3%，后者是专为阅读理解任务设计的多个模型的集合。我们的单一模型达到了 86.5% 的准确率，仍然比最先进的集成模型高 2.4%。

![](https://gitee.com/Xiaoyingzi09/note-book/raw/master/NoteBook/NLP/Bert/ALBERT/ALBERT%20A%20LITE%20BERT%20FOR/table%2010png.png)

表 10：SQuAD 和 RACE 基准的最新结果。

## 5 讨论(总结)

虽然 ALBERT-xxlarge 的参数比 BERT-large 少，并且得到了明显更好的结果，但由于其更大的结构，它的计算成本更高。 因此，下一步重要的是通过稀疏注意力（Child et al., 2019）和块注意力（Shen et al., 2018）等方法加快 ALBERT 的训练和推理速度。 可以提供额外表示能力的正交研究线包括困难示例挖掘（Mikolov 等人，2013）和更有效的语言建模训练（Yang 等人，2019 年）。 此外，尽管我们有令人信服的证据表明句子顺序预测是一种更一致有用的学习任务，可以产生更好的语言表示，但我们假设可能有更多维度尚未被当前的自监督训练损失捕获，这可能会产生额外的表示 结果表示的权力。
