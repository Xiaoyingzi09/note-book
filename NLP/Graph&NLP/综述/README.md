# Graph Neural Networks for Natural Language Processing: A Survey 

# 用于自然语言处理的图神经网络：综述

## 摘要

深度学习已成为应对自然语言处理 (NLP) 中各种任务的主要方法。 尽管文本输入通常表示为一系列标记，但有很多 NLP 问题可以用图结构最好地表达。 因此，人们对为大量 NLP 任务开发新的图深度学习技术的兴趣激增。 在本次调查中，我们全面概述了用于自然语言处理的图神经网络 (GNN)。 我们提出了一种新的 NLP GNN 分类法，它沿三个轴系统地组织了 NLP 的 GNN 现有研究：图构建、图表示学习和基于图的编码器-解码器模型。 我们进一步介绍了大量利用 GNN 功能的 NLP 应用程序，并总结了相应的基准数据集、评估指标和开源代码。 最后，我们讨论了充分利用 GNN 进行 NLP 的各种突出挑战以及未来的研究方向。 据我们所知，这是对用于自然语言处理的图神经网络的第一个全面概述。

关键词：图神经网络，自然语言处理，图深度学习

## 1 前言

深度学习已成为当今自然语言处理 (NLP) 中处理各种任务的主要方法，尤其是在对大规模文本语料库进行操作时。 传统上，文本序列在 NLP 任务中被认为是一包令牌，例如 BoW 和 TF-IDF。 随着 Word Embeddings 技术（Mikolov 等人，2013 年；Pennington 等人，2014 年）的近期成功，句子在 NLP 任务中通常表示为一系列标记。 因此，流行的深度学习技术，例如循环神经网络（Schuster 和 Paliwal，1997）和卷积神经网络（Krizhevsky 等，2012）已广泛应用于文本序列建模。

然而，有各种各样的 NLP 问题可以用图结构最好地表达。 例如，文本序列中的句子结构信息（即句法分析树，如依赖和选区分析树）可以通过结合特定任务的知识来增加原始序列数据。 类似地，序列数据中的语义信息（即语义解析图，如抽象含义表示图和信息提取图）也可以用来增强原始序列数据。 因此，这些图结构数据可以编码实体标记之间复杂的成对关系，以学习更多信息表示。

不幸的是，由于图数据的复杂性，例如不规则结构和不同大小的节点，对欧几里德数据（例如图像）或序列数据（例如文本）具有破坏性的深度学习技术不能立即适用于图结构数据 邻居。 因此，这一差距推动了图深度学习研究的潮流，尤其是图神经网络 (GNN) 的开发（Kipf 和 Welling，2016 年；Defferrard 等人，2016 年；Hamilton 等人，2017a）。

这波图深度学习和 NLP 交叉领域的研究浪潮影响了各种 NLP 任务。 人们对应用和开发不同 GNN 变体的兴趣激增，并在许多 NLP 任务中取得了相当大的成功，包括句子分类等分类任务（Henaff 等人，2015 年；Huang 和 Carley，2019 年）、语义角色标记罗和 赵 (2020); 桂等人。  (2019) 和关系抽取 (Qu et al., 2020; Sahu et al., 2019)，生成机器翻译等任务 (Bastings et al., 2017; Beck et al., 2018)、问题生成 (Pan et al., 2018)  al., 2020; Sachan et al., 2020) 和总结 (Fernandes et al., 2019; Yasunaga et al., 2017)。 尽管这些现有研究取得了成功，但 NLP 图的深度学习仍然遇到许多挑战，即，

- 自动将原始文本序列数据转换为高度图结构化的数据。这种挑战在 NLP 中是深远的，因为大多数 NLP 任务都涉及使用文本序列作为原始输入。 从文本序列自动构建图以利用底层结构信息是利用图神经网络解决 NLP 问题的关键步骤。
- 正确确定图表示学习技术。 提出专门设计的 GNN 来学习不同图结构数据的独特特征（例如无向图、有向图、多关系图和异构图）至关重要。
- 对复杂数据进行有效建模。 这种挑战很重要，因为许多 NLP 任务涉及学习基于图的输入与其他高度结构化的输出数据（例如序列、树以及节点和边的多种类型的图数据）之间的映射。

在本次调查中，我们将首次全面概述用于自然语言处理的图神经网络。 我们的调查对机器学习和 NLP 社区都是及时的，它涵盖了相关且有趣的主题，包括 NLP 的自动图构建、NLP 的图表示学习、各种基于 GNN 的高级编码器-解码器模型（即 graph2seq、graph2tree 和 graph2graph） 用于 NLP，以及 GNN 在各种 NLP 任务中的应用。 我们强调我们的主要贡献如下：

- 我们提出了一种新的 NLP GNN 分类法，它沿三个轴系统地组织了 NLP 的 GNN 现有研究：图构建、图表示学习和基于图的编码器-解码器模型。
- 我们对各种 NLP 任务的最先进的基于 GNN 的方法进行了最全面的概述。 我们提供了基于领域知识和语义空间的各种图构建方法的详细描述和必要的比较，针对各种类型的图结构数据的图表示学习方法，基于 GNN 的编码器 - 解码器模型给出了不同的输入和输出数据类型组合。
- 我们介绍了大量利用 GNN 强大功能的 NLP 应用程序，包括它们如何沿着三个关键组件（即图构建、图表示学习和嵌入初始化）处理这些 NLP 任务，以及提供相应的基准数据集， 评估指标和开源代码。
- 我们概述了充分利用 GNN 进行 NLP 的各种突出挑战，并为富有成果和未探索的研究方向提供讨论和建议。

调查的其余部分结构如下。 第 2 节从图的角度回顾了 NLP 问题，然后简要介绍了一些具有代表性的传统基于图的解决 NLP 问题的方法。 第 3 节详细阐述了图神经网络的基本基础和方法，图神经网络是一类直接对图结构数据进行操作的现代神经网络。 我们还提供了整个调查中使用的符号列表。 第 4 节重点介绍两种主要的图构建方法，即静态图构建和动态图构建，用于在各种 NLP 任务中构建图结构化输入。 第 5 节讨论了各种图表示学习技术，这些技术直接在为各种 NLP 任务构建的图上进行操作。 第 6 节首先介绍了典型的 Seq2Seq 模型，然后讨论了用于 NLP 任务的两种典型的基于图的编码器-解码器模型（即图到树和图到图模型）。 第 7 节讨论了 12 个使用 GNN 的典型 NLP 应用程序，同时提供了所有应用程序及其子任务、评估指标和开源代码的摘要。 第 8 节讨论了用于 NLP 的 GNN 的各种一般挑战，并指出了未来的研究方向。最后，第 9 节总结了本文。 分类法沿三个轴系统地组织了用于 NLP 方法的 GNN：图构建、图表示学习、编码器解码器模型，其应用如图 1 所示。

![]()

图 1：分类法，它沿三个轴系统地组织 NLP 的 GNN：图构建、图表示学习、编码器-解码器模型和应用程序。

















